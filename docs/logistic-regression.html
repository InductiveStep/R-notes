<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Logistic regression | Using R for social research</title>
  <meta name="description" content="These are some notes on using R" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Logistic regression | Using R for social research" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are some notes on using R" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Logistic regression | Using R for social research" />
  
  <meta name="twitter:description" content="These are some notes on using R" />
  

<meta name="author" content="Andi Fugard  (almost@gmail.com, @InductiveStep)" />


<meta name="date" content="2020-11-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="categorical-predictors-and-interactions.html"/>
<link rel="next" href="complex-surveys.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="libs/table1-1.0/table1_defaults.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="starting-rstudio.html"><a href="starting-rstudio.html"><i class="fa fa-check"></i><b>1</b> Starting RStudio</a>
<ul>
<li class="chapter" data-level="1.1" data-path="starting-rstudio.html"><a href="starting-rstudio.html#download-install-and-run"><i class="fa fa-check"></i><b>1.1</b> Download, install, and run</a></li>
<li class="chapter" data-level="1.2" data-path="starting-rstudio.html"><a href="starting-rstudio.html#make-a-new-r-notebook-file"><i class="fa fa-check"></i><b>1.2</b> Make a new R Notebook file</a></li>
<li class="chapter" data-level="1.3" data-path="starting-rstudio.html"><a href="starting-rstudio.html#save-the-file"><i class="fa fa-check"></i><b>1.3</b> Save the file</a></li>
<li class="chapter" data-level="1.4" data-path="starting-rstudio.html"><a href="starting-rstudio.html#run-the-example-r-command"><i class="fa fa-check"></i><b>1.4</b> Run the example R command</a></li>
<li class="chapter" data-level="1.5" data-path="starting-rstudio.html"><a href="starting-rstudio.html#clear-it-and-try-a-sum"><i class="fa fa-check"></i><b>1.5</b> Clear it and try a sum</a></li>
<li class="chapter" data-level="1.6" data-path="starting-rstudio.html"><a href="starting-rstudio.html#did-that-help"><i class="fa fa-check"></i><b>1.6</b> Did that help?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="starting-r.html"><a href="starting-r.html"><i class="fa fa-check"></i><b>2</b> Starting R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="starting-r.html"><a href="starting-r.html#arithmetic"><i class="fa fa-check"></i><b>2.1</b> Arithmetic</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="starting-r.html"><a href="starting-r.html#activities"><i class="fa fa-check"></i><b>2.1.1</b> Activities</a></li>
<li class="chapter" data-level="2.1.2" data-path="starting-r.html"><a href="starting-r.html#answers"><i class="fa fa-check"></i><b>2.1.2</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="starting-r.html"><a href="starting-r.html#variables"><i class="fa fa-check"></i><b>2.2</b> Variables</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="starting-r.html"><a href="starting-r.html#activity"><i class="fa fa-check"></i><b>2.2.1</b> Activity</a></li>
<li class="chapter" data-level="2.2.2" data-path="starting-r.html"><a href="starting-r.html#answer"><i class="fa fa-check"></i><b>2.2.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="starting-r.html"><a href="starting-r.html#a-note-on-variable-names"><i class="fa fa-check"></i><b>2.3</b> A note on variable names</a></li>
<li class="chapter" data-level="2.4" data-path="starting-r.html"><a href="starting-r.html#vectors"><i class="fa fa-check"></i><b>2.4</b> Vectors</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="starting-r.html"><a href="starting-r.html#activity-1"><i class="fa fa-check"></i><b>2.4.1</b> Activity</a></li>
<li class="chapter" data-level="2.4.2" data-path="starting-r.html"><a href="starting-r.html#answer-1"><i class="fa fa-check"></i><b>2.4.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="starting-r.html"><a href="starting-r.html#functions"><i class="fa fa-check"></i><b>2.5</b> Functions</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="starting-r.html"><a href="starting-r.html#activity-2"><i class="fa fa-check"></i><b>2.5.1</b> Activity</a></li>
<li class="chapter" data-level="2.5.2" data-path="starting-r.html"><a href="starting-r.html#answer-2"><i class="fa fa-check"></i><b>2.5.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="starting-r.html"><a href="starting-r.html#more-functions"><i class="fa fa-check"></i><b>2.6</b> More functions</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="starting-r.html"><a href="starting-r.html#activity-3"><i class="fa fa-check"></i><b>2.6.1</b> Activity</a></li>
<li class="chapter" data-level="2.6.2" data-path="starting-r.html"><a href="starting-r.html#answer-3"><i class="fa fa-check"></i><b>2.6.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="starting-r.html"><a href="starting-r.html#data-frames"><i class="fa fa-check"></i><b>2.7</b> Data frames</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="starting-r.html"><a href="starting-r.html#activity-4"><i class="fa fa-check"></i><b>2.7.1</b> Activity</a></li>
<li class="chapter" data-level="2.7.2" data-path="starting-r.html"><a href="starting-r.html#answer-4"><i class="fa fa-check"></i><b>2.7.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="starting-r.html"><a href="starting-r.html#loading-data-frames-from-a-file"><i class="fa fa-check"></i><b>2.8</b> Loading data frames from a file</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="starting-r.html"><a href="starting-r.html#activity-5"><i class="fa fa-check"></i><b>2.8.1</b> Activity</a></li>
<li class="chapter" data-level="2.8.2" data-path="starting-r.html"><a href="starting-r.html#answer-5"><i class="fa fa-check"></i><b>2.8.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="starting-r.html"><a href="starting-r.html#packages"><i class="fa fa-check"></i><b>2.9</b> Packages</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="starting-r.html"><a href="starting-r.html#activity-6"><i class="fa fa-check"></i><b>2.9.1</b> Activity</a></li>
<li class="chapter" data-level="2.9.2" data-path="starting-r.html"><a href="starting-r.html#answer-6"><i class="fa fa-check"></i><b>2.9.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="starting-r.html"><a href="starting-r.html#the-end"><i class="fa fa-check"></i><b>2.10</b> The end!</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html"><i class="fa fa-check"></i><b>3</b> Visualising data in the tidyverse</a>
<ul>
<li class="chapter" data-level="3.1" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#getting-setup"><i class="fa fa-check"></i><b>3.1</b> Getting setup</a></li>
<li class="chapter" data-level="3.2" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#an-interlude-on-functions"><i class="fa fa-check"></i><b>3.2</b> An interlude on functions</a></li>
<li class="chapter" data-level="3.3" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#a-scatterplot-in-ggplot"><i class="fa fa-check"></i><b>3.3</b> A scatterplot in ggplot</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#warm-up-activity"><i class="fa fa-check"></i><b>3.3.1</b> Warm-up activity</a></li>
<li class="chapter" data-level="3.3.2" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#answer-7"><i class="fa fa-check"></i><b>3.3.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#another-aesthetic-colour"><i class="fa fa-check"></i><b>3.4</b> Another aesthetic: colour</a></li>
<li class="chapter" data-level="3.5" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#another-geom-jitter"><i class="fa fa-check"></i><b>3.5</b> Another geom: jitter</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#activity-to-develop-your-help-searching-skill"><i class="fa fa-check"></i><b>3.5.1</b> Activity to develop your help-searching skill!</a></li>
<li class="chapter" data-level="3.5.2" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#answer-8"><i class="fa fa-check"></i><b>3.5.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#aggregatingsummarising-data-by-group"><i class="fa fa-check"></i><b>3.6</b> Aggregating/summarising data by group</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#activity-7"><i class="fa fa-check"></i><b>3.6.1</b> Activity</a></li>
<li class="chapter" data-level="3.6.2" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#answer-9"><i class="fa fa-check"></i><b>3.6.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#pipes"><i class="fa fa-check"></i><b>3.7</b> Pipes</a></li>
<li class="chapter" data-level="3.8" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#plot-the-mean-life-expectancy-by-continent"><i class="fa fa-check"></i><b>3.8</b> Plot the mean life expectancy by continent</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#actvity"><i class="fa fa-check"></i><b>3.8.1</b> Actvity</a></li>
<li class="chapter" data-level="3.8.2" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#answer-10"><i class="fa fa-check"></i><b>3.8.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#yet-another-geom-line"><i class="fa fa-check"></i><b>3.9</b> Yet another geom: line</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#activity-8"><i class="fa fa-check"></i><b>3.9.1</b> Activity</a></li>
<li class="chapter" data-level="3.9.2" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#answer-11"><i class="fa fa-check"></i><b>3.9.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#filtering-data-along-the-pipeline"><i class="fa fa-check"></i><b>3.10</b> Filtering data along the pipeline</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#activity-9"><i class="fa fa-check"></i><b>3.10.1</b> Activity</a></li>
<li class="chapter" data-level="3.10.2" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#answer-12"><i class="fa fa-check"></i><b>3.10.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#other-handy-tools-select-slice-bind-and-arrange"><i class="fa fa-check"></i><b>3.11</b> Other handy tools: select, slice, bind, and arrange</a></li>
<li class="chapter" data-level="3.12" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#filtering-for-members-of-a-vector"><i class="fa fa-check"></i><b>3.12</b> Filtering for members of a vector</a></li>
<li class="chapter" data-level="3.13" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#final-challenge"><i class="fa fa-check"></i><b>3.13</b> Final challenge</a>
<ul>
<li class="chapter" data-level="3.13.1" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#activity-10"><i class="fa fa-check"></i><b>3.13.1</b> Activity</a></li>
<li class="chapter" data-level="3.13.2" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#answer-13"><i class="fa fa-check"></i><b>3.13.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="3.14" data-path="visualising-data-in-the-tidyverse.html"><a href="visualising-data-in-the-tidyverse.html#more-ideas-for-visualisations"><i class="fa fa-check"></i><b>3.14</b> More ideas for visualisations</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="p-values-and-confidence-intervals.html"><a href="p-values-and-confidence-intervals.html"><i class="fa fa-check"></i><b>4</b> P-values and confidence intervals</a>
<ul>
<li class="chapter" data-level="4.1" data-path="p-values-and-confidence-intervals.html"><a href="p-values-and-confidence-intervals.html#correlation-recap"><i class="fa fa-check"></i><b>4.1</b> Correlation recap</a></li>
<li class="chapter" data-level="4.2" data-path="p-values-and-confidence-intervals.html"><a href="p-values-and-confidence-intervals.html#testing-null-hypotheses"><i class="fa fa-check"></i><b>4.2</b> Testing null-hypotheses</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="p-values-and-confidence-intervals.html"><a href="p-values-and-confidence-intervals.html#what-can-samples-look-like-when-the-true-correlation-is-0"><i class="fa fa-check"></i><b>4.2.1</b> What can samples look like when the true correlation is 0?</a></li>
<li class="chapter" data-level="4.2.2" data-path="p-values-and-confidence-intervals.html"><a href="p-values-and-confidence-intervals.html#understanding-actual-data-in-relation-to-these-simulations"><i class="fa fa-check"></i><b>4.2.2</b> Understanding actual data in relation to these simulations</a></li>
<li class="chapter" data-level="4.2.3" data-path="p-values-and-confidence-intervals.html"><a href="p-values-and-confidence-intervals.html#so-what-is-a-p-value"><i class="fa fa-check"></i><b>4.2.3</b> So, what is a p-value?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="p-values-and-confidence-intervals.html"><a href="p-values-and-confidence-intervals.html#confidence-intervals"><i class="fa fa-check"></i><b>4.3</b> Confidence intervals</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="p-values-and-confidence-intervals.html"><a href="p-values-and-confidence-intervals.html#simulating-confidence"><i class="fa fa-check"></i><b>4.3.1</b> Simulating confidence</a></li>
<li class="chapter" data-level="4.3.2" data-path="p-values-and-confidence-intervals.html"><a href="p-values-and-confidence-intervals.html#what-is-a-confidence-interval-then"><i class="fa fa-check"></i><b>4.3.2</b> What is a confidence interval, then?</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="p-values-and-confidence-intervals.html"><a href="p-values-and-confidence-intervals.html#further-reading"><i class="fa fa-check"></i><b>4.4</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>5</b> Linear regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="linear-regression.html"><a href="linear-regression.html#before-we-begin"><i class="fa fa-check"></i><b>5.1</b> Before we begin</a></li>
<li class="chapter" data-level="5.2" data-path="linear-regression.html"><a href="linear-regression.html#the-dataset"><i class="fa fa-check"></i><b>5.2</b> The dataset</a></li>
<li class="chapter" data-level="5.3" data-path="linear-regression.html"><a href="linear-regression.html#interlude-on-methodology"><i class="fa fa-check"></i><b>5.3</b> Interlude on methodology</a></li>
<li class="chapter" data-level="5.4" data-path="linear-regression.html"><a href="linear-regression.html#descriptives"><i class="fa fa-check"></i><b>5.4</b> Descriptives</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="linear-regression.html"><a href="linear-regression.html#activity-11"><i class="fa fa-check"></i><b>5.4.1</b> Activity</a></li>
<li class="chapter" data-level="5.4.2" data-path="linear-regression.html"><a href="linear-regression.html#answer-14"><i class="fa fa-check"></i><b>5.4.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="linear-regression.html"><a href="linear-regression.html#prep-to-understand-the-simplest-regression-model"><i class="fa fa-check"></i><b>5.5</b> Prep to understand the simplest regression model</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="linear-regression.html"><a href="linear-regression.html#activity-12"><i class="fa fa-check"></i><b>5.5.1</b> Activity</a></li>
<li class="chapter" data-level="5.5.2" data-path="linear-regression.html"><a href="linear-regression.html#answer-15"><i class="fa fa-check"></i><b>5.5.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="linear-regression.html"><a href="linear-regression.html#the-simplest-regression-model-intercept-only-model"><i class="fa fa-check"></i><b>5.6</b> The simplest regression model: intercept-only model</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="linear-regression.html"><a href="linear-regression.html#activity-13"><i class="fa fa-check"></i><b>5.6.1</b> Activity</a></li>
<li class="chapter" data-level="5.6.2" data-path="linear-regression.html"><a href="linear-regression.html#answer-16"><i class="fa fa-check"></i><b>5.6.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="linear-regression.html"><a href="linear-regression.html#adding-a-slope-to-the-regression-model"><i class="fa fa-check"></i><b>5.7</b> Adding a slope to the regression model</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="linear-regression.html"><a href="linear-regression.html#activity-14"><i class="fa fa-check"></i><b>5.7.1</b> Activity</a></li>
<li class="chapter" data-level="5.7.2" data-path="linear-regression.html"><a href="linear-regression.html#answer-17"><i class="fa fa-check"></i><b>5.7.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="linear-regression.html"><a href="linear-regression.html#residuals"><i class="fa fa-check"></i><b>5.8</b> Residuals</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="linear-regression.html"><a href="linear-regression.html#activity-15"><i class="fa fa-check"></i><b>5.8.1</b> Activity</a></li>
<li class="chapter" data-level="5.8.2" data-path="linear-regression.html"><a href="linear-regression.html#answer-18"><i class="fa fa-check"></i><b>5.8.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="linear-regression.html"><a href="linear-regression.html#comparing-models"><i class="fa fa-check"></i><b>5.9</b> Comparing models</a></li>
<li class="chapter" data-level="5.10" data-path="linear-regression.html"><a href="linear-regression.html#regression-with-two-or-more-predictors"><i class="fa fa-check"></i><b>5.10</b> Regression with two or more predictors</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="linear-regression.html"><a href="linear-regression.html#activity-16"><i class="fa fa-check"></i><b>5.10.1</b> Activity</a></li>
<li class="chapter" data-level="5.10.2" data-path="linear-regression.html"><a href="linear-regression.html#answer-19"><i class="fa fa-check"></i><b>5.10.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="linear-regression.html"><a href="linear-regression.html#interpreting-regression-models-with-two-or-more-predictors"><i class="fa fa-check"></i><b>5.11</b> Interpreting regression models with two or more predictors</a></li>
<li class="chapter" data-level="5.12" data-path="linear-regression.html"><a href="linear-regression.html#optional-that-pesky-negative-intercept"><i class="fa fa-check"></i><b>5.12</b> Optional: that pesky negative intercept</a>
<ul>
<li class="chapter" data-level="5.12.1" data-path="linear-regression.html"><a href="linear-regression.html#activity-17"><i class="fa fa-check"></i><b>5.12.1</b> Activity</a></li>
<li class="chapter" data-level="5.12.2" data-path="linear-regression.html"><a href="linear-regression.html#answer-20"><i class="fa fa-check"></i><b>5.12.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="linear-regression.html"><a href="linear-regression.html#finally-confidence-intervals"><i class="fa fa-check"></i><b>5.13</b> Finally: confidence intervals</a></li>
<li class="chapter" data-level="5.14" data-path="linear-regression.html"><a href="linear-regression.html#very-optional-extras"><i class="fa fa-check"></i><b>5.14</b> Very optional extras</a>
<ul>
<li class="chapter" data-level="5.14.1" data-path="linear-regression.html"><a href="linear-regression.html#making-functions"><i class="fa fa-check"></i><b>5.14.1</b> Making functions</a></li>
<li class="chapter" data-level="5.14.2" data-path="linear-regression.html"><a href="linear-regression.html#another-way-to-make-scatterplots-ggally"><i class="fa fa-check"></i><b>5.14.2</b> Another way to make scatterplots: GGally</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html"><i class="fa fa-check"></i><b>6</b> Linear regression diagnostics</a>
<ul>
<li class="chapter" data-level="6.1" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#before-we-begin-1"><i class="fa fa-check"></i><b>6.1</b> Before we begin</a></li>
<li class="chapter" data-level="6.2" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#the-dataset-1"><i class="fa fa-check"></i><b>6.2</b> The dataset</a></li>
<li class="chapter" data-level="6.3" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#fit-a-regression-model"><i class="fa fa-check"></i><b>6.3</b> Fit a regression model</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#activity-18"><i class="fa fa-check"></i><b>6.3.1</b> Activity</a></li>
<li class="chapter" data-level="6.3.2" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#answer-21"><i class="fa fa-check"></i><b>6.3.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#checking-for-normally-distributed-residuals"><i class="fa fa-check"></i><b>6.4</b> Checking for normally distributed residuals</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#base-r-histogram"><i class="fa fa-check"></i><b>6.4.1</b> Base R histogram</a></li>
<li class="chapter" data-level="6.4.2" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#quantile-comparison-plot"><i class="fa fa-check"></i><b>6.4.2</b> Quantile-comparison plot</a></li>
<li class="chapter" data-level="6.4.3" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#statistical-test-of-normality"><i class="fa fa-check"></i><b>6.4.3</b> Statistical test of normality</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#checking-constant-residual-variance"><i class="fa fa-check"></i><b>6.5</b> Checking constant residual variance</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#activity-20"><i class="fa fa-check"></i><b>6.5.1</b> Activity</a></li>
<li class="chapter" data-level="6.5.2" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#answer-23"><i class="fa fa-check"></i><b>6.5.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#checking-for-relationships-between-residuals-and-predicted-outcome-or-predictors"><i class="fa fa-check"></i><b>6.6</b> Checking for relationships between residuals and predicted outcome or predictors</a></li>
<li class="chapter" data-level="6.7" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#checking-linearity"><i class="fa fa-check"></i><b>6.7</b> Checking linearity</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#what-should-be-linear-in-a-linear-model"><i class="fa fa-check"></i><b>6.7.1</b> What should be linear in a linear model?</a></li>
<li class="chapter" data-level="6.7.2" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#checking-for-linearity"><i class="fa fa-check"></i><b>6.7.2</b> Checking for linearity</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#checking-influence-leave-one-out-analyses"><i class="fa fa-check"></i><b>6.8</b> Checking influence: leave-one-out analyses</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#residual-outliers"><i class="fa fa-check"></i><b>6.8.1</b> Residual outliers</a></li>
<li class="chapter" data-level="6.8.2" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#cooks-distance"><i class="fa fa-check"></i><b>6.8.2</b> Cook’s distance</a></li>
<li class="chapter" data-level="6.8.3" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#dfbeta-and-close-sibling-dfbetas"><i class="fa fa-check"></i><b>6.8.3</b> DFBETA and (close sibling) DFBETAS</a></li>
<li class="chapter" data-level="6.8.4" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#view-them-all"><i class="fa fa-check"></i><b>6.8.4</b> View them all</a></li>
<li class="chapter" data-level="6.8.5" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#so-er-what-should-we-do-with-potentially-influential-observations"><i class="fa fa-check"></i><b>6.8.5</b> So, er, what should we do with “potentially influential” observations…?</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#checking-the-variance-inflation-factors-vifs"><i class="fa fa-check"></i><b>6.9</b> Checking the variance inflation factors (VIFs)</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#activity-22"><i class="fa fa-check"></i><b>6.9.1</b> Activity</a></li>
<li class="chapter" data-level="6.9.2" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#answer-25"><i class="fa fa-check"></i><b>6.9.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#the-challenge"><i class="fa fa-check"></i><b>6.10</b> The challenge</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#activity-23"><i class="fa fa-check"></i><b>6.10.1</b> Activity</a></li>
<li class="chapter" data-level="6.10.2" data-path="linear-regression-diagnostics.html"><a href="linear-regression-diagnostics.html#answer-26"><i class="fa fa-check"></i><b>6.10.2</b> Answer</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html"><i class="fa fa-check"></i><b>7</b> Categorical predictors and interactions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#before-we-begin-2"><i class="fa fa-check"></i><b>7.1</b> Before we begin</a></li>
<li class="chapter" data-level="7.2" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#the-dataset-2"><i class="fa fa-check"></i><b>7.2</b> The dataset</a></li>
<li class="chapter" data-level="7.3" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#factors"><i class="fa fa-check"></i><b>7.3</b> Factors</a></li>
<li class="chapter" data-level="7.4" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#visualising-the-data"><i class="fa fa-check"></i><b>7.4</b> Visualising the data</a></li>
<li class="chapter" data-level="7.5" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#the-punchline-occupation-type-does-predict-prestige"><i class="fa fa-check"></i><b>7.5</b> The punchline: occupation type does predict prestige</a></li>
<li class="chapter" data-level="7.6" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#understanding-factors-in-regression-models"><i class="fa fa-check"></i><b>7.6</b> Understanding factors in regression models</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#how-are-categorical-variables-encoded"><i class="fa fa-check"></i><b>7.6.1</b> How are categorical variables encoded?</a></li>
<li class="chapter" data-level="7.6.2" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#how-are-binary-two-level-categorical-predictors-encoded"><i class="fa fa-check"></i><b>7.6.2</b> How are binary (two-level) categorical predictors encoded?</a></li>
<li class="chapter" data-level="7.6.3" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#categorical-predictors-with-3-or-more-levels"><i class="fa fa-check"></i><b>7.6.3</b> Categorical predictors with 3 or more levels</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#interpreting-the-coefficients"><i class="fa fa-check"></i><b>7.7</b> Interpreting the coefficients</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#activity-25"><i class="fa fa-check"></i><b>7.7.1</b> Activity</a></li>
<li class="chapter" data-level="7.7.2" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#answer-28"><i class="fa fa-check"></i><b>7.7.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#checking-all-combinations"><i class="fa fa-check"></i><b>7.8</b> Checking all combinations</a></li>
<li class="chapter" data-level="7.9" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#the-intercept-is-not-always-the-mean-of-the-comparison-group"><i class="fa fa-check"></i><b>7.9</b> The intercept is not always the mean of the comparison group</a></li>
<li class="chapter" data-level="7.10" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#recap"><i class="fa fa-check"></i><b>7.10</b> Recap</a></li>
<li class="chapter" data-level="7.11" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#challenge"><i class="fa fa-check"></i><b>7.11</b> Challenge</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#activity-26"><i class="fa fa-check"></i><b>7.11.1</b> Activity</a></li>
<li class="chapter" data-level="7.11.2" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#answers-1"><i class="fa fa-check"></i><b>7.11.2</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#brief-introduction-to-interactions"><i class="fa fa-check"></i><b>7.12</b> Brief introduction to interactions</a>
<ul>
<li class="chapter" data-level="7.12.1" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#what-is-an-interaction"><i class="fa fa-check"></i><b>7.12.1</b> What is an interaction?</a></li>
<li class="chapter" data-level="7.12.2" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#how-to-test-for-interactions-in-r"><i class="fa fa-check"></i><b>7.12.2</b> How to test for interactions in R</a></li>
<li class="chapter" data-level="7.12.3" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#understanding-interactions"><i class="fa fa-check"></i><b>7.12.3</b> Understanding interactions</a></li>
<li class="chapter" data-level="7.12.4" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#further-reading-1"><i class="fa fa-check"></i><b>7.12.4</b> Further reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="logistic-regression.html"><a href="logistic-regression.html#setup"><i class="fa fa-check"></i><b>8.1</b> Setup</a></li>
<li class="chapter" data-level="8.2" data-path="logistic-regression.html"><a href="logistic-regression.html#the-dataset-3"><i class="fa fa-check"></i><b>8.2</b> The dataset</a></li>
<li class="chapter" data-level="8.3" data-path="logistic-regression.html"><a href="logistic-regression.html#warmup-activity"><i class="fa fa-check"></i><b>8.3</b> Warmup activity</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#activity-27"><i class="fa fa-check"></i><b>8.3.1</b> Activity</a></li>
<li class="chapter" data-level="8.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#answer-29"><i class="fa fa-check"></i><b>8.3.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="logistic-regression.html"><a href="logistic-regression.html#the-punchline"><i class="fa fa-check"></i><b>8.4</b> The punchline</a></li>
<li class="chapter" data-level="8.5" data-path="logistic-regression.html"><a href="logistic-regression.html#intermezzo-parametric-versus-nonparametric"><i class="fa fa-check"></i><b>8.5</b> Intermezzo: parametric versus nonparametric</a></li>
<li class="chapter" data-level="8.6" data-path="logistic-regression.html"><a href="logistic-regression.html#glms"><i class="fa fa-check"></i><b>8.6</b> What is a generalised linear model?</a></li>
<li class="chapter" data-level="8.7" data-path="logistic-regression.html"><a href="logistic-regression.html#what-is-the-log-function-again"><i class="fa fa-check"></i><b>8.7</b> What is the log function again…?</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="logistic-regression.html"><a href="logistic-regression.html#log-arithmetic"><i class="fa fa-check"></i><b>8.7.1</b> The arithmetic</a></li>
<li class="chapter" data-level="8.7.2" data-path="logistic-regression.html"><a href="logistic-regression.html#why-log"><i class="fa fa-check"></i><b>8.7.2</b> Why log?</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="logistic-regression.html"><a href="logistic-regression.html#intercept-only-models-again"><i class="fa fa-check"></i><b>8.8</b> Intercept-only models again</a></li>
<li class="chapter" data-level="8.9" data-path="logistic-regression.html"><a href="logistic-regression.html#odds-and-log-odds"><i class="fa fa-check"></i><b>8.9</b> Odds and log odds</a></li>
<li class="chapter" data-level="8.10" data-path="logistic-regression.html"><a href="logistic-regression.html#back-to-that-intercept"><i class="fa fa-check"></i><b>8.10</b> Back to that intercept</a></li>
<li class="chapter" data-level="8.11" data-path="logistic-regression.html"><a href="logistic-regression.html#interpret-slopes"><i class="fa fa-check"></i><b>8.11</b> Interpreting model slopes</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="logistic-regression.html"><a href="logistic-regression.html#interpret-on-the-log-odds-scale"><i class="fa fa-check"></i><b>8.11.1</b> Interpret on the log-odds scale</a></li>
<li class="chapter" data-level="8.11.2" data-path="logistic-regression.html"><a href="logistic-regression.html#interpret-using-the-divide-by-4-approximation"><i class="fa fa-check"></i><b>8.11.2</b> Interpret using the “divide-by-4” approximation</a></li>
<li class="chapter" data-level="8.11.3" data-path="logistic-regression.html"><a href="logistic-regression.html#interpret-using-odds"><i class="fa fa-check"></i><b>8.11.3</b> Interpret using odds</a></li>
<li class="chapter" data-level="8.11.4" data-path="logistic-regression.html"><a href="logistic-regression.html#interpret-using-predicted-probabilities"><i class="fa fa-check"></i><b>8.11.4</b> Interpret using predicted probabilities</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="logistic-regression.html"><a href="logistic-regression.html#diagnostics"><i class="fa fa-check"></i><b>8.12</b> Diagnostics</a>
<ul>
<li class="chapter" data-level="8.12.1" data-path="logistic-regression.html"><a href="logistic-regression.html#check-the-residual-distribution"><i class="fa fa-check"></i><b>8.12.1</b> Check the residual distribution</a></li>
<li class="chapter" data-level="8.12.2" data-path="logistic-regression.html"><a href="logistic-regression.html#check-that-the-residual-mean-is-constant"><i class="fa fa-check"></i><b>8.12.2</b> Check that the residual mean is constant</a></li>
<li class="chapter" data-level="8.12.3" data-path="logistic-regression.html"><a href="logistic-regression.html#linearity-of-predictors"><i class="fa fa-check"></i><b>8.12.3</b> Linearity of predictors</a></li>
<li class="chapter" data-level="8.12.4" data-path="logistic-regression.html"><a href="logistic-regression.html#influence"><i class="fa fa-check"></i><b>8.12.4</b> Influence</a></li>
<li class="chapter" data-level="8.12.5" data-path="logistic-regression.html"><a href="logistic-regression.html#multicolinearity"><i class="fa fa-check"></i><b>8.12.5</b> Multicolinearity</a></li>
</ul></li>
<li class="chapter" data-level="8.13" data-path="logistic-regression.html"><a href="logistic-regression.html#a-challenge"><i class="fa fa-check"></i><b>8.13</b> A challenge</a>
<ul>
<li class="chapter" data-level="8.13.1" data-path="logistic-regression.html"><a href="logistic-regression.html#activity-31"><i class="fa fa-check"></i><b>8.13.1</b> Activity</a></li>
<li class="chapter" data-level="8.13.2" data-path="logistic-regression.html"><a href="logistic-regression.html#an-answer"><i class="fa fa-check"></i><b>8.13.2</b> (An) Answer</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="complex-surveys.html"><a href="complex-surveys.html"><i class="fa fa-check"></i><b>9</b> Complex surveys</a>
<ul>
<li class="chapter" data-level="9.1" data-path="complex-surveys.html"><a href="complex-surveys.html#readings"><i class="fa fa-check"></i><b>9.1</b> Readings</a></li>
<li class="chapter" data-level="9.2" data-path="complex-surveys.html"><a href="complex-surveys.html#the-dataset-4"><i class="fa fa-check"></i><b>9.2</b> The dataset</a></li>
<li class="chapter" data-level="9.3" data-path="complex-surveys.html"><a href="complex-surveys.html#the-components-of-a-survey-design"><i class="fa fa-check"></i><b>9.3</b> The components of a survey design</a></li>
<li class="chapter" data-level="9.4" data-path="complex-surveys.html"><a href="complex-surveys.html#describing-the-data"><i class="fa fa-check"></i><b>9.4</b> Describing the data</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="complex-surveys.html"><a href="complex-surveys.html#activity-32"><i class="fa fa-check"></i><b>9.4.1</b> Activity</a></li>
<li class="chapter" data-level="9.4.2" data-path="complex-surveys.html"><a href="complex-surveys.html#answer-33"><i class="fa fa-check"></i><b>9.4.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="complex-surveys.html"><a href="complex-surveys.html#fitting-a-glm"><i class="fa fa-check"></i><b>9.5</b> Fitting a GLM</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="complex-surveys.html"><a href="complex-surveys.html#activity-33"><i class="fa fa-check"></i><b>9.5.1</b> Activity</a></li>
<li class="chapter" data-level="9.5.2" data-path="complex-surveys.html"><a href="complex-surveys.html#answer-34"><i class="fa fa-check"></i><b>9.5.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="complex-surveys.html"><a href="complex-surveys.html#slopes"><i class="fa fa-check"></i><b>9.6</b> Slopes</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="complex-surveys.html"><a href="complex-surveys.html#activity-34"><i class="fa fa-check"></i><b>9.6.1</b> Activity</a></li>
<li class="chapter" data-level="9.6.2" data-path="complex-surveys.html"><a href="complex-surveys.html#answer-35"><i class="fa fa-check"></i><b>9.6.2</b> Answer</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="complex-surveys.html"><a href="complex-surveys.html#diagnostics-1"><i class="fa fa-check"></i><b>9.7</b> Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mediation-analysis.html"><a href="mediation-analysis.html"><i class="fa fa-check"></i><b>10</b> Mediation analysis</a>
<ul>
<li class="chapter" data-level="10.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#simulated-example"><i class="fa fa-check"></i><b>10.1</b> Simulated Example</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#make-up-some-data"><i class="fa fa-check"></i><b>10.1.1</b> Make up some data</a></li>
<li class="chapter" data-level="10.1.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#analyse-it"><i class="fa fa-check"></i><b>10.1.2</b> Analyse it</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>11</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Using R for social research</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression" class="section level1" number="8">
<h1><span class="header-section-number">Chapter 8</span> Logistic regression</h1>
<p>By the end of this chapter you will understand:</p>
<ul>
<li>How generalised linear models (GLMs) generalise regression to deal with a wider variety of distributions of data.</li>
<li>How to fit a GLM to binary data (also known as logistic regression).</li>
<li>How to interpret the results.</li>
<li>Which diagnostics from linear models do and don’t apply here.</li>
</ul>
<p>Much herein will be familiar from what we covered for linear regression. The main challenge is that the outcome variable is on the log-odds scale, which makes it trickier to interpret the model intercept and slopes. I provide four different ways to make sense of them, so you can choose which makes most sense to you.</p>
<p>This <a href="https://twitter.com/ChelseaParlett/status/1304436259926896640?s=20">short video</a> might be helpful too.</p>
<div id="setup" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Setup</h2>
<p>Let’s load the <code>tidyverse</code>.</p>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="logistic-regression.html#cb446-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<p>I’m also going to use <code>knitr</code> to make tables look prettier:</p>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb447-1"><a href="logistic-regression.html#cb447-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(knitr)</span></code></pre></div>
</div>
<div id="the-dataset-3" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> The dataset</h2>
<p>We will look at a different dataset in this chapter (HURRAH; <a href="psid1975.csv">download it here</a>), as analysed by Mroz (1987) and spotted in Fox and Weisberg (2019). The data are from the US Panel Study of Income Dynamics (PSID) in 1975: 753 married white women aged between 30 and 60.</p>
<p>The outcome variable we will examine is whether participants participated in the labour force. So it will be worth thinking through your (implicit or otherwise) theories of what processes might be operating in 1975.</p>
<p>We would expect a more diverse sample these days. You might also ponder what extra information you would want to know and why. For what it’s worth, I’m curious what both wife and husband thought about gender roles and what sort of childcare was available. I’m not sure if it’s relevant, but I am also curious to know how many participants were bisexual (we can’t tell, but it is often wrongly assumed that people in a heterosexual marriage are both heterosexual).</p>
<table>
<colgroup>
<col width="53%" />
<col width="46%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>lfp</code></td>
<td>labour-force participation at some point during the year (no/yes).</td>
</tr>
<tr class="even">
<td><code>lfp_yes</code></td>
<td>same as above, but with yes = 1, no = 0</td>
</tr>
<tr class="odd">
<td><code>k5</code></td>
<td>number of children 5 years old or younger.</td>
</tr>
<tr class="even">
<td><code>k618</code></td>
<td>number of children 6 to 18 years old.</td>
</tr>
<tr class="odd">
<td><code>age</code></td>
<td>in years.</td>
</tr>
<tr class="even">
<td><code>wc</code></td>
<td>wife’s college attendance (no/yes).</td>
</tr>
<tr class="odd">
<td><code>hc</code></td>
<td>husband’s college attendance (no/yes).</td>
</tr>
<tr class="even">
<td><code>lwg</code></td>
<td>log expected wage rate; for women in the labour force, the actual wage rate; for women not in the labour force, an imputed value based on the regression of <code>lwg</code> on the other variables.</td>
</tr>
<tr class="odd">
<td><code>inc</code></td>
<td>family income exclusive of wife’s income (in $1000s).</td>
</tr>
</tbody>
</table>
<p>Read in the data:</p>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="logistic-regression.html#cb448-1" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;psid1975.csv&quot;</span>)</span></code></pre></div>
<p>Here is how to view a random sample of rows. (The <code>set.seed</code> command is optional – I am just using it so that I keep getting the same random sample. If you’re curious, <a href="https://en.wikipedia.org/w/index.php?title=Random_seed&amp;oldid=933429432">Wikipedia’s article</a> is currently fine.)</p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="logistic-regression.html#cb449-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb449-2"><a href="logistic-regression.html#cb449-2" aria-hidden="true" tabindex="-1"></a>dat <span class="sc">%&gt;%</span></span>
<span id="cb449-3"><a href="logistic-regression.html#cb449-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_sample</span>(<span class="at">n =</span> <span class="dv">10</span>)</span></code></pre></div>
<pre><code>##    lfp lfp_yes k5 k618 age  wc  hc       lwg    inc
## 1   no       0  0    2  43  no  no 1.2282799 14.550
## 2   no       0  1    1  30  no yes 0.9791328 22.000
## 3   no       0  0    0  53  no  no 0.8861951 21.574
## 4   no       0  0    3  39  no  no 0.8532125 28.363
## 5  yes       1  0    2  35 yes  no 1.6046872  5.120
## 6  yes       1  0    2  36 yes yes 1.7037485 23.600
## 7  yes       1  0    2  48  no  no 1.5448993  9.000
## 8   no       0  0    0  50 yes yes 1.7312460 63.200
## 9   no       0  1    0  30  no yes 1.0167637 19.392
## 10 yes       1  0    1  48 yes yes 1.6549002 70.750</code></pre>
<p>The <code>lfp_yes</code> variable was calculated using the line below. This might come in handy for your analyses should you wish to dichotomise a variable.</p>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb451-1"><a href="logistic-regression.html#cb451-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(dat<span class="sc">$</span>lfp <span class="sc">==</span> <span class="st">&quot;yes&quot;</span>)</span></code></pre></div>
</div>
<div id="warmup-activity" class="section level2 tabset" number="8.3">
<h2><span class="header-section-number">8.3</span> Warmup activity</h2>
<div id="activity-27" class="section level3" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Activity</h3>
<ol style="list-style-type: lower-alpha">
<li>What do you think might predict participation in the labour force? Have a think <em>before looking at the descriptives</em> and write down your thoughts.</li>
<li>Set <code>wc</code> and <code>hc</code> to factors.</li>
<li>Generate a table of descriptive statistics (“Table 1”) using a method of your choosing.</li>
</ol>
</div>
<div id="answer-29" class="section level3" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> Answer</h3>
<p><strong>a. What do you think might predict participation in the labour force? Have a think before looking at the descriptives.</strong></p>
<p>It was too late for me since I had already peeked and can only report my hindsight bias!</p>
<p><strong>b. Set <code>wc</code> and <code>hc</code> to factors.</strong></p>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="logistic-regression.html#cb452-1" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>wc <span class="ot">&lt;-</span> <span class="fu">factor</span>(dat<span class="sc">$</span>wc)</span>
<span id="cb452-2"><a href="logistic-regression.html#cb452-2" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>hc <span class="ot">&lt;-</span> <span class="fu">factor</span>(dat<span class="sc">$</span>hc)</span></code></pre></div>
<p><strong>c. Generate a table of descriptive statistics (“Table 1”) using a method of your choosing.</strong></p>
<p>Here is one we haven’t used yet, in the <code>table1</code> package. Here is how to use it with a pipe; recall that the dot in <code>data = .</code> is how to refer to the data frame that flowed in via the pipe from the <code>select</code> line above:</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="logistic-regression.html#cb453-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(table1)</span>
<span id="cb453-2"><a href="logistic-regression.html#cb453-2" aria-hidden="true" tabindex="-1"></a>dat <span class="sc">%&gt;%</span></span>
<span id="cb453-3"><a href="logistic-regression.html#cb453-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>lfp_yes) <span class="sc">%&gt;%</span></span>
<span id="cb453-4"><a href="logistic-regression.html#cb453-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table1</span>(<span class="sc">~</span> ., <span class="at">data =</span> .)</span></code></pre></div>
<div class="Rtable1"><table class="Rtable1">
<thead>
<tr>
<th class='rowlabel firstrow lastrow'></th>
<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=753)</span></span></th>
</tr>
</thead>
<tbody>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>lfp</span></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>no</td>
<td>325 (43.2%)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>yes</td>
<td class='lastrow'>428 (56.8%)</td>
</tr>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>k5</span></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>Mean (SD)</td>
<td>0.238 (0.524)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>Median [Min, Max]</td>
<td class='lastrow'>0 [0, 3.00]</td>
</tr>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>k618</span></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>Mean (SD)</td>
<td>1.35 (1.32)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>Median [Min, Max]</td>
<td class='lastrow'>1.00 [0, 8.00]</td>
</tr>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>age</span></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>Mean (SD)</td>
<td>42.5 (8.07)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>Median [Min, Max]</td>
<td class='lastrow'>43.0 [30.0, 60.0]</td>
</tr>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>wc</span></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>no</td>
<td>541 (71.8%)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>yes</td>
<td class='lastrow'>212 (28.2%)</td>
</tr>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>hc</span></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>no</td>
<td>458 (60.8%)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>yes</td>
<td class='lastrow'>295 (39.2%)</td>
</tr>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>lwg</span></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>Mean (SD)</td>
<td>1.10 (0.588)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>Median [Min, Max]</td>
<td class='lastrow'>1.07 [-2.05, 3.22]</td>
</tr>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>inc</span></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>Mean (SD)</td>
<td>20.1 (11.6)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>Median [Min, Max]</td>
<td class='lastrow'>17.7 [-0.0290, 96.0]</td>
</tr>
</tbody>
</table>
</div>
<p>It is straightforward to generate descriptives by group. Since we will be exploring predictors of labour-force participation, it makes sense to group the analyses by whether the participant has worked or not during the past year:</p>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="logistic-regression.html#cb454-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table1</span>(<span class="sc">~</span> k5 <span class="sc">+</span> k618 <span class="sc">+</span> age <span class="sc">+</span> inc <span class="sc">|</span> lfp, <span class="at">data =</span> dat)</span></code></pre></div>
<div class="Rtable1"><table class="Rtable1">
<thead>
<tr>
<th class='rowlabel firstrow lastrow'></th>
<th class='firstrow lastrow'><span class='stratlabel'>no<br><span class='stratn'>(N=325)</span></span></th>
<th class='firstrow lastrow'><span class='stratlabel'>yes<br><span class='stratn'>(N=428)</span></span></th>
<th class='firstrow lastrow'><span class='stratlabel'>Overall<br><span class='stratn'>(N=753)</span></span></th>
</tr>
</thead>
<tbody>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>k5</span></td>
<td class='firstrow'></td>
<td class='firstrow'></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>Mean (SD)</td>
<td>0.366 (0.637)</td>
<td>0.140 (0.392)</td>
<td>0.238 (0.524)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>Median [Min, Max]</td>
<td class='lastrow'>0 [0, 3.00]</td>
<td class='lastrow'>0 [0, 2.00]</td>
<td class='lastrow'>0 [0, 3.00]</td>
</tr>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>k618</span></td>
<td class='firstrow'></td>
<td class='firstrow'></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>Mean (SD)</td>
<td>1.36 (1.33)</td>
<td>1.35 (1.32)</td>
<td>1.35 (1.32)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>Median [Min, Max]</td>
<td class='lastrow'>1.00 [0, 7.00]</td>
<td class='lastrow'>1.00 [0, 8.00]</td>
<td class='lastrow'>1.00 [0, 8.00]</td>
</tr>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>age</span></td>
<td class='firstrow'></td>
<td class='firstrow'></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>Mean (SD)</td>
<td>43.3 (8.47)</td>
<td>42.0 (7.72)</td>
<td>42.5 (8.07)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>Median [Min, Max]</td>
<td class='lastrow'>44.0 [30.0, 60.0]</td>
<td class='lastrow'>42.0 [30.0, 60.0]</td>
<td class='lastrow'>43.0 [30.0, 60.0]</td>
</tr>
<tr>
<td class='rowlabel firstrow'><span class='varlabel'>inc</span></td>
<td class='firstrow'></td>
<td class='firstrow'></td>
<td class='firstrow'></td>
</tr>
<tr>
<td class='rowlabel'>Mean (SD)</td>
<td>21.7 (12.7)</td>
<td>18.9 (10.6)</td>
<td>20.1 (11.6)</td>
</tr>
<tr>
<td class='rowlabel lastrow'>Median [Min, Max]</td>
<td class='lastrow'>19.0 [1.50, 96.0]</td>
<td class='lastrow'>17.1 [-0.0290, 91.0]</td>
<td class='lastrow'>17.7 [-0.0290, 96.0]</td>
</tr>
</tbody>
</table>
</div>
<p>And now you have looked - you can no longer hypothesise what might be going on!</p>
<p>Here’s a picture that took too long, but shows what’s possible. It was built up part-by-part, so to understand it you probably need to devote some time to disassembling it.</p>
<p>The labels on each data point are the <em>n</em>’s, so you can see that the pattern beyond 6 children is due to individual households.</p>
<p>I also explicitly named the package <code>dplyr</code> for the <code>select</code> and <code>recode</code> commands because the same names are used for functions in the <code>car</code> package.</p>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="logistic-regression.html#cb455-1" aria-hidden="true" tabindex="-1"></a>dat <span class="sc">%&gt;%</span></span>
<span id="cb455-2"><a href="logistic-regression.html#cb455-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(k5, k618, lfp_yes) <span class="sc">%&gt;%</span></span>
<span id="cb455-3"><a href="logistic-regression.html#cb455-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">names_to =</span> <span class="st">&quot;children_age&quot;</span>,</span>
<span id="cb455-4"><a href="logistic-regression.html#cb455-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">&quot;children_num&quot;</span>,</span>
<span id="cb455-5"><a href="logistic-regression.html#cb455-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">cols =</span> <span class="sc">!</span>lfp_yes) <span class="sc">%&gt;%</span></span>
<span id="cb455-6"><a href="logistic-regression.html#cb455-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">children_age =</span> dplyr<span class="sc">::</span><span class="fu">recode</span>(children_age,</span>
<span id="cb455-7"><a href="logistic-regression.html#cb455-7" aria-hidden="true" tabindex="-1"></a>                               <span class="at">k5 =</span> <span class="st">&quot;0 to 5&quot;</span>,</span>
<span id="cb455-8"><a href="logistic-regression.html#cb455-8" aria-hidden="true" tabindex="-1"></a>                               <span class="at">k618 =</span> <span class="st">&quot;6 to 18&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb455-9"><a href="logistic-regression.html#cb455-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(children_age, children_num) <span class="sc">%&gt;%</span></span>
<span id="cb455-10"><a href="logistic-regression.html#cb455-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">perc_lfp =</span> <span class="fu">mean</span>(lfp_yes)<span class="sc">*</span><span class="dv">100</span>,</span>
<span id="cb455-11"><a href="logistic-regression.html#cb455-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb455-12"><a href="logistic-regression.html#cb455-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> children_num,</span>
<span id="cb455-13"><a href="logistic-regression.html#cb455-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> perc_lfp,</span>
<span id="cb455-14"><a href="logistic-regression.html#cb455-14" aria-hidden="true" tabindex="-1"></a>             <span class="at">colour =</span> children_age,</span>
<span id="cb455-15"><a href="logistic-regression.html#cb455-15" aria-hidden="true" tabindex="-1"></a>             <span class="at">label =</span> n)) <span class="sc">+</span></span>
<span id="cb455-16"><a href="logistic-regression.html#cb455-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb455-17"><a href="logistic-regression.html#cb455-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb455-18"><a href="logistic-regression.html#cb455-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_text</span>(<span class="at">colour =</span> <span class="st">&quot;black&quot;</span>, </span>
<span id="cb455-19"><a href="logistic-regression.html#cb455-19" aria-hidden="true" tabindex="-1"></a>              <span class="at">nudge_y =</span> <span class="dv">1</span>,</span>
<span id="cb455-20"><a href="logistic-regression.html#cb455-20" aria-hidden="true" tabindex="-1"></a>              <span class="at">nudge_x =</span> <span class="fl">0.1</span>,</span>
<span id="cb455-21"><a href="logistic-regression.html#cb455-21" aria-hidden="true" tabindex="-1"></a>              <span class="at">hjust =</span> <span class="dv">0</span>,</span>
<span id="cb455-22"><a href="logistic-regression.html#cb455-22" aria-hidden="true" tabindex="-1"></a>              <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb455-23"><a href="logistic-regression.html#cb455-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlab</span>(<span class="st">&quot;Number of children&quot;</span>) <span class="sc">+</span></span>
<span id="cb455-24"><a href="logistic-regression.html#cb455-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylab</span>(<span class="st">&quot;% women in paid employment&quot;</span>) <span class="sc">+</span></span>
<span id="cb455-25"><a href="logistic-regression.html#cb455-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">colour =</span> <span class="st">&quot;Children age&quot;</span>)</span></code></pre></div>
<pre><code>## `summarise()` regrouping output by &#39;children_age&#39; (override with `.groups` argument)</code></pre>
<p><img src="R-notes_files/figure-html/age-work-graph-1.png" width="672" /></p>
</div>
</div>
<div id="the-punchline" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> The punchline</h2>
<p>We will spend some time going into the arithmetic of logistic regression model coefficients since it helps interpret what the models mean.</p>
<p>So that you have a sense of where this is heading, here is how to fit a model predicting whether women were in paid employment from the number of children in the family aged 5 or younger (<code>k5</code>) and 6 to 18 (<code>k618</code>):</p>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="logistic-regression.html#cb457-1" aria-hidden="true" tabindex="-1"></a>mod_kids <span class="ot">&lt;-</span> <span class="fu">glm</span>(lfp_yes <span class="sc">~</span> k5 <span class="sc">+</span> k618, <span class="at">data =</span> dat, <span class="at">family =</span> binomial)</span></code></pre></div>
<p>This is the intercept-only model:</p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="logistic-regression.html#cb458-1" aria-hidden="true" tabindex="-1"></a>mod_0 <span class="ot">&lt;-</span> <span class="fu">glm</span>(lfp_yes <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> dat, <span class="at">family =</span> binomial)</span></code></pre></div>
<p>And this command compares the two:</p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="logistic-regression.html#cb459-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod_0, mod_kids, <span class="at">test =</span> <span class="st">&quot;Chi&quot;</span>)</span></code></pre></div>
<p>To get a summary use:</p>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="logistic-regression.html#cb460-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_kids)</span></code></pre></div>
<p>Here are confidence intervals:</p>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="logistic-regression.html#cb461-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Confint</span>(mod_kids)</span></code></pre></div>
<p>The R code involved is almost identical to what we used for linear regression. The main challenge will be interpreting the slopes, but I will share some tips to make this relatively painless.</p>
</div>
<div id="intermezzo-parametric-versus-nonparametric" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> Intermezzo: parametric versus nonparametric</h2>
<blockquote>
<p>“The term nonparametric may have some historical significance and meaning for theoretical statisticians, but it only serves to confuse applied statisticians.”</p>
</blockquote>
<p>—G. E. Noether (1984)</p>
<p>Many introductory social science statistics courses explain that if your data are normally distributed, then you use parametric statistics, otherwise you use nonparametric statistics. Or that the <em>data</em> can be parametric or nonparametric.</p>
<p><em>Both claims are false.</em></p>
<p>The parametric versus nonparametric distinction refers to statistical <em>models</em>, not the data. It simply refers to whether the distributions involved are assumed to have a known mathematical form. If a model assumes a particular distribution, then it is parametric (Wolfowitz, 1942). We have already seen that you can check (to some extent) whether model assumptions are satisfied.</p>
<p>You can think of parameters as being like knobs on an old radio. Tuning the knobs changes the parameters.</p>
<p><img src="radio.png" width="300" /></p>
<p>The normal distribution has two parameters, mean and standard deviation:</p>
<p><img src="R-notes_files/figure-html/unnamed-chunk-312-.gif" width="672" /></p>
<p>We will be exploring a parametric approach to modelling binary data (whether or not someone was in paid employment) in this chapter, using a special case of the binomial distribution with size = 1. There is one parameter: the probability, and values are either 0 or 1.</p>
<p><img src="R-notes_files/figure-html/unnamed-chunk-313-.gif" width="288" /></p>
<p>This distribution is somewhat easier to grasp than the curve of a normal distribution, though we will encounter a logistic-al irritation in using it in practice.</p>
</div>
<div id="glms" class="section level2" number="8.6">
<h2><span class="header-section-number">8.6</span> What is a generalised linear model?</h2>
<p>As the name suggests, <em>generalised linear models</em> generalise the linear model. (Not to be confused with a <em>general</em> linear model – different thing.) They are initialised as GLM, which is pronounced “glim.”</p>
<p>GLMs have three components (see Fox and Weisberg, 2019, pp. 272-275 for more detail):</p>
<ol style="list-style-type: decimal">
<li><p>A specification of the <em>error distribution</em>. For linear models, this is a normal distribution.</p></li>
<li><p>A linear formula linking outcome to predictors and the <span class="math inline">\(\beta\)</span>’s to be estimated:
<span class="math display">\[
g(y) = \beta_0 + \beta_1 x_1 + \beta_1x_2 + \cdots + \beta_n x_n
\]</span>
The right hand side is identical to linear models. The left hand side, <span class="math inline">\(g(y)\)</span>, is mildly different to the usual <span class="math inline">\(y\)</span> and is there to ensure the maths works for different shapes of distribution.</p></li>
<li><p>GLMs also have a <em>link function</em> – that’s the <span class="math inline">\(g\)</span>. For linear models, <span class="math inline">\(g(y) = y\)</span>, what is known as the <em>identity link</em> – it just passes the input unchanged to the output. For logistic regression, <span class="math inline">\(g\)</span> is log-odds, also known as the <em>logit</em>. The formula then is
<span class="math display">\[
\log\frac{p}{1-p}= \beta_0 + \beta_1 x_1 + \beta_1x_2 + \cdots + \beta_n x_n
\]</span>
where <span class="math inline">\(p\)</span> is the probability of an event happening (e.g., being in work).</p></li>
</ol>
<p>So, a linear regression model is a generalised linear model with a normal error distribution and an identity link. Logistic regression is a generalised linear model with a binomial error distribution and a log-odds (logit) link.</p>
<p>The error distribution and link are together called the <em>family</em>. By default, <code>glm</code> chooses a sensible link for you so in practice you just have to name the error distribution.</p>
</div>
<div id="what-is-the-log-function-again" class="section level2" number="8.7">
<h2><span class="header-section-number">8.7</span> What is the log function again…?</h2>
<p>To interpret logistic regression models we need to understand log-odds and to understand log-odds we need to grasp logs. I’m aware that it may be some time since you last used them!</p>
<p>There are two aspects to revise: the arithmetic and why logs are typically used.</p>
<div id="log-arithmetic" class="section level3 tabset" number="8.7.1">
<h3><span class="header-section-number">8.7.1</span> The arithmetic</h3>
<p>The arithmetic is easy: the <em>log</em> is simply the inverse of “to the power of” or exponentiation.</p>
<p>Here is an example of exponentiation:</p>
<p><span class="math display">\[
10^n = \underbrace{10 \times \dots \times 10}_{\mathrm{n\ times}}
\]</span></p>
<p>So <span class="math inline">\(10^2 = 100\)</span> and <span class="math inline">\(10^4 = 10000\)</span> and so on. More generally, with <span class="math inline">\(b^n\)</span>, the <span class="math inline">\(b\)</span> is called the <em>base</em> and <span class="math inline">\(n\)</span> is the <em>exponent</em>.</p>
<p>Log just reverses this.</p>
<p>Suppose with want to find out what to raise 10 to the power of to get 1000, then we just calculate</p>
<p><span class="math display">\[
\log_{10}(100)
\]</span>
In R:</p>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb462-1"><a href="logistic-regression.html#cb462-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="dv">100</span>, <span class="at">base =</span> <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## [1] 2</code></pre>
<p>So <span class="math inline">\({\color{magenta} {10}}^{\color{blue} 2} = 100\)</span> and <span class="math inline">\(\log_{\color{magenta} {10}}(100) = \color{blue} 2\)</span>.</p>
<p>Let’s try another base, 2. Two to the power of five is…</p>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb464-1"><a href="logistic-regression.html#cb464-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">^</span><span class="dv">5</span></span></code></pre></div>
<pre><code>## [1] 32</code></pre>
<p>… 32.</p>
<div id="activity-28" class="section level4" number="8.7.1.1">
<h4><span class="header-section-number">8.7.1.1</span> Activity</h4>
<p>Two to the power of what is 1024…?</p>
</div>
<div id="answer-30" class="section level4" number="8.7.1.2">
<h4><span class="header-section-number">8.7.1.2</span> Answer</h4>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="logistic-regression.html#cb466-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="dv">1024</span>, <span class="at">base =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 10</code></pre>
<p>It’s 10. Let’s check.</p>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb468-1"><a href="logistic-regression.html#cb468-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">^</span><span class="dv">10</span></span></code></pre></div>
<pre><code>## [1] 1024</code></pre>
<p>So much for the arithmetic; onto some intutions for why it is used…</p>
</div>
</div>
<div id="why-log" class="section level3" number="8.7.2">
<h3><span class="header-section-number">8.7.2</span> Why log?</h3>
<p>Sadly, these days we are <a href="https://www.weforum.org/agenda/2020/04/covid-19-spread-logarithmic-graph/">very aware</a> of exponential and log functions since they are used when communicating data on the Covid-19 pandemic.</p>
<p>Suppose some quantity doubles over time; let’s take as an example the number of cat GIFs in my saved images over time:</p>
<p><img src="spot.gif" /></p>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb470-1"><a href="logistic-regression.html#cb470-1" aria-hidden="true" tabindex="-1"></a>doubles <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">month    =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">9</span>,</span>
<span id="cb470-2"><a href="logistic-regression.html#cb470-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">cat_GIFs =</span> <span class="dv">2</span><span class="sc">^</span>month)</span>
<span id="cb470-3"><a href="logistic-regression.html#cb470-3" aria-hidden="true" tabindex="-1"></a>doubles <span class="sc">%&gt;%</span></span>
<span id="cb470-4"><a href="logistic-regression.html#cb470-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&quot;Month&quot;</span>, <span class="st">&quot;Number of cat GIFs&quot;</span>))</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">Month</th>
<th align="right">Number of cat GIFs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">16</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="right">32</td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td align="right">64</td>
</tr>
<tr class="even">
<td align="right">7</td>
<td align="right">128</td>
</tr>
<tr class="odd">
<td align="right">8</td>
<td align="right">256</td>
</tr>
<tr class="even">
<td align="right">9</td>
<td align="right">512</td>
</tr>
</tbody>
</table>
<p>I started off with one GIF. As each month passes, the number of GIFs doubles. To find the number of GIFs at a particular time, use <span class="math inline">\(2^{\mathit{month}}\)</span>. Here is 5 months into my stash:</p>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="logistic-regression.html#cb471-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">^</span><span class="dv">5</span></span></code></pre></div>
<pre><code>## [1] 32</code></pre>
<p>Here is a picture of GIF growth:</p>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="logistic-regression.html#cb473-1" aria-hidden="true" tabindex="-1"></a>doubles <span class="sc">%&gt;%</span></span>
<span id="cb473-2"><a href="logistic-regression.html#cb473-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(month, cat_GIFs)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb473-3"><a href="logistic-regression.html#cb473-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Month&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Number of cat GIFs&quot;</span>) <span class="sc">+</span></span>
<span id="cb473-4"><a href="logistic-regression.html#cb473-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">9</span>,<span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb473-5"><a href="logistic-regression.html#cb473-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="dv">2</span><span class="sc">^</span>x, <span class="at">n =</span> <span class="dv">400</span>)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-320-1.png" width="672" /></p>
<p>As we saw <a href="logistic-regression.html#log-arithmetic">above</a>, we can also run <span class="math inline">\(2^\mathit{month}\)</span> in reverse. Given a particular number of cat GIFs, say 32, how many times did the original number double to get there? Simply calculate <span class="math inline">\(\log_2(32)\)</span>:</p>
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb474-1"><a href="logistic-regression.html#cb474-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="dv">32</span>, <span class="at">base =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<p>Often it is easier to see exponential relationships and any changes in relationships over time if they are plotted on a straight line. A way to straighten out exponential growth is to log the y-axis whilst keeping the original values at each tick point on the axis:</p>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb476-1"><a href="logistic-regression.html#cb476-1" aria-hidden="true" tabindex="-1"></a>doubles <span class="sc">%&gt;%</span></span>
<span id="cb476-2"><a href="logistic-regression.html#cb476-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(month, cat_GIFs)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb476-3"><a href="logistic-regression.html#cb476-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_trans</span>(<span class="at">y =</span> <span class="st">&quot;log2&quot;</span>) <span class="sc">+</span> <span class="co"># this line transforms the axis</span></span>
<span id="cb476-4"><a href="logistic-regression.html#cb476-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Month&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Number of cat GIFs&quot;</span>) <span class="sc">+</span></span>
<span id="cb476-5"><a href="logistic-regression.html#cb476-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">9</span>,<span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb476-6"><a href="logistic-regression.html#cb476-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="dv">2</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">9</span>,<span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb476-7"><a href="logistic-regression.html#cb476-7" aria-hidden="true" tabindex="-1"></a>     <span class="co"># this scale_y line says where to place the labels</span></span>
<span id="cb476-8"><a href="logistic-regression.html#cb476-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="dv">2</span><span class="sc">^</span>x, <span class="at">n =</span> <span class="dv">400</span>)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-322-1.png" width="672" /></p>
<p>We can also log the values, so that the y-axis now says how many times the number of GIFs has doubled.</p>
<div class="sourceCode" id="cb477"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb477-1"><a href="logistic-regression.html#cb477-1" aria-hidden="true" tabindex="-1"></a>doubles <span class="sc">%&gt;%</span></span>
<span id="cb477-2"><a href="logistic-regression.html#cb477-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(month, <span class="fu">log</span>(cat_GIFs,<span class="dv">2</span>))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb477-3"><a href="logistic-regression.html#cb477-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Month&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Logged number of cat GIFs&quot;</span>) <span class="sc">+</span></span>
<span id="cb477-4"><a href="logistic-regression.html#cb477-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb477-5"><a href="logistic-regression.html#cb477-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">9</span>,<span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb477-6"><a href="logistic-regression.html#cb477-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) x, <span class="at">n =</span> <span class="dv">400</span>)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-323-1.png" width="672" /></p>
<p>I hope that provides some intuitions for what the log function does. Roughly, it transforms a process that multiplies, and can be hard to understand on the original scale, into a process that is additive.</p>
</div>
</div>
<div id="intercept-only-models-again" class="section level2" number="8.8">
<h2><span class="header-section-number">8.8</span> Intercept-only models again</h2>
<p>For linear regression, the intercept in an intercept-only model was the mean of the the outcome variable. Intercepts in GLMs work the same; however, now we have the mild complication of the link function which is part of the arithmetic that makes GLMs work.</p>
<p>The mean of the binary variable, <code>lfp_yes</code>, is:</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb478-1"><a href="logistic-regression.html#cb478-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(dat<span class="sc">$</span>lfp_yes)</span></code></pre></div>
<pre><code>## [1] 0.5683931</code></pre>
<p>This is the proportion of women who were in paid employment (do you see why the mean is a proportion here?).</p>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb480-1"><a href="logistic-regression.html#cb480-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(dat<span class="sc">$</span>lfp)</span></code></pre></div>
<pre><code>## 
##  no yes 
## 325 428</code></pre>
<p>Now let’s see what logistic regression gives us:</p>
<div class="sourceCode" id="cb482"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb482-1"><a href="logistic-regression.html#cb482-1" aria-hidden="true" tabindex="-1"></a>mod_intercept <span class="ot">&lt;-</span> <span class="fu">glm</span>(lfp_yes <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> dat, <span class="at">family =</span> binomial)</span>
<span id="cb482-2"><a href="logistic-regression.html#cb482-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_intercept)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = lfp_yes ~ 1, family = binomial, data = dat)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.296  -1.296   1.063   1.063   1.063  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.27530    0.07358   3.742 0.000183 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1029.7  on 752  degrees of freedom
## Residual deviance: 1029.7  on 752  degrees of freedom
## AIC: 1031.7
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Most of that will look very familiar – the coefficients, standard error, p-values (though now of a <span class="math inline">\(z\)</span>-value rather than <span class="math inline">\(t\)</span>) – however, the intercept is <em>not</em> the mean of <code>lfp_yes</code>.</p>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb484-1"><a href="logistic-regression.html#cb484-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_intercept)</span></code></pre></div>
<pre><code>## (Intercept) 
##    0.275298</code></pre>
<p>This is actually the <em>log-odds</em> of being in paid work, which is arithmetically related to the probability. So onto the next bit of arithmetic…</p>
</div>
<div id="odds-and-log-odds" class="section level2" number="8.9">
<h2><span class="header-section-number">8.9</span> Odds and log odds</h2>
<p>Odds are alternatives to probabilities for quantifying uncertainty. The probability of getting a 20 on one roll of a fair 20-sided die are <span class="math inline">\(\frac{1}{20}\)</span> or 0.05. The odds are 1 to 19 or <span class="math inline">\(\frac{1}{19}\)</span>.</p>
<p>There are 20 possible outcomes, each equally likely. We are interested in the odds of one of those outcomes. The odds are the ratio of the probability that an event <em>will</em> happen to the probability that it will <em>not</em>. For the 20-sided die case, since every outcome is equally likely, we can just use the number of outcomes directly in the formula.</p>
<p>More generally, if the probability of an event is <span class="math inline">\(p\)</span>, then the odds are</p>
<p><span class="math display">\[
\mathit{odds} = \frac{p}{1-p}
\]</span></p>
<p>If the probability of an event happening is <span class="math inline">\(p\)</span>, then <span class="math inline">\(1-p\)</span> is the probability that it will not happen, hence the bottom line of that fraction.</p>
<p>If you do some arithmetic (or Google) you will see that it is possible to go in reverse:</p>
<p><span class="math display">\[
p = \frac{\mathit{odds}}{1+\mathit{odds}}
\]</span></p>
<p>The log odds are the log of the odds, usually the <a href="https://en.wikipedia.org/wiki/Natural_logarithm">natural log</a>, i.e., log base <span class="math inline">\(e = 2.718282\ldots\)</span>, which is what R provides by default. This can be written <span class="math inline">\(\log_e\)</span> or <span class="math inline">\(\ln\)</span>. So the log odds of getting a 20 on one throw of a 20-sided die are:</p>
<div class="sourceCode" id="cb486"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb486-1"><a href="logistic-regression.html#cb486-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">19</span>)</span></code></pre></div>
<pre><code>## [1] -2.944439</code></pre>
<p>Personally, I don’t find <span class="math inline">\(-2.94\)</span> a particularly meaningful number! And actually, later I will share some tricks so that you don’t have to even think about what it means. However, I think it is important to get a sense of some example landmark odds and log odds along a range of probabilities. Fifteen minutes spent staring at this table will come in handy (<code>Inf</code> is “infinity”).</p>
<table>
<thead>
<tr class="header">
<th align="right">Probability</th>
<th align="right">Odds</th>
<th align="right">Log odds (logit)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.0</td>
<td align="right">0.00</td>
<td align="right">-Inf</td>
</tr>
<tr class="even">
<td align="right">0.1</td>
<td align="right">0.11</td>
<td align="right">-2.20</td>
</tr>
<tr class="odd">
<td align="right">0.2</td>
<td align="right">0.25</td>
<td align="right">-1.39</td>
</tr>
<tr class="even">
<td align="right">0.3</td>
<td align="right">0.43</td>
<td align="right">-0.85</td>
</tr>
<tr class="odd">
<td align="right">0.4</td>
<td align="right">0.67</td>
<td align="right">-0.41</td>
</tr>
<tr class="even">
<td align="right">0.5</td>
<td align="right">1.00</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="right">0.6</td>
<td align="right">1.50</td>
<td align="right">0.41</td>
</tr>
<tr class="even">
<td align="right">0.7</td>
<td align="right">2.33</td>
<td align="right">0.85</td>
</tr>
<tr class="odd">
<td align="right">0.8</td>
<td align="right">4.00</td>
<td align="right">1.39</td>
</tr>
<tr class="even">
<td align="right">0.9</td>
<td align="right">9.00</td>
<td align="right">2.20</td>
</tr>
<tr class="odd">
<td align="right">1.0</td>
<td align="right">Inf</td>
<td align="right">Inf</td>
</tr>
</tbody>
</table>
<p>Here are clues for where to look:</p>
<ul>
<li>Look at what the odds and log odds are when the probability is 0.5.</li>
<li>Look at probabilities 0 and 1.</li>
<li>Look for symmetry in the log odds above and below probability 0.5.</li>
<li>The odds are also symmetric around 0.5, though this is a (little) more difficult to see. Try 0.2 and 0.8 probability. The odds of a 0.2 probability are
<span class="math display">\[
\frac{0.2}{1 - 0.2} = \frac{0.2}{0.8} = \frac{2}{8} = \frac{1}{4} = 0.25
\]</span>
The odds of a 0.8 probability are
<span class="math display">\[
\frac{0.8}{1 - 0.8} = \frac{0.8}{0.2} = \frac{8}{2} = \frac{4}{1} = 4
\]</span>
So the fraction just turns upside down.</li>
</ul>
<p>Finally, here is a picture showing the relationship between log-odds and probability:</p>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb488-1"><a href="logistic-regression.html#cb488-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb488-2"><a href="logistic-regression.html#cb488-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="dv">6</span>) <span class="sc">+</span></span>
<span id="cb488-3"><a href="logistic-regression.html#cb488-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.5</span>, <span class="at">colour =</span> <span class="st">&quot;darkgrey&quot;</span>) <span class="sc">+</span></span>
<span id="cb488-4"><a href="logistic-regression.html#cb488-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> plogis, <span class="at">n =</span> <span class="dv">200</span>) <span class="sc">+</span></span>
<span id="cb488-5"><a href="logistic-regression.html#cb488-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Probability&quot;</span>) <span class="sc">+</span></span>
<span id="cb488-6"><a href="logistic-regression.html#cb488-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Log-odds (logit)&quot;</span>)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-330-1.png" width="672" /></p>
<p>Note how the relationship is mostly non-linear, except for a patch in the middle where it is linear. The log-odds stretch out to negative and plus infinity, whereas probabilities are bound between 0 and 1. The probability for a log-odds of 6 is 0.9975274. The probability for a log-odds of 15, far off the scale on this graph, is 0.9999939. It never quite reaches 1 or, in the opposite direction, 0.</p>
<p>To summarise then, probability, odds, and log-odds are different and interchangeable ways to quantify how sure you are that something is going to happen.</p>
</div>
<div id="back-to-that-intercept" class="section level2" number="8.10">
<h2><span class="header-section-number">8.10</span> Back to that intercept</h2>
<p>We know the proportion of women in paid work:</p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb489-1"><a href="logistic-regression.html#cb489-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(dat<span class="sc">$</span>lfp_yes)</span></code></pre></div>
<pre><code>## [1] 0.5683931</code></pre>
<p>Assuming a random sample, this is also an estimate of the probability that someone chosen at random from the larger population will be in paid work. Let’s then calculate the odds:</p>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="logistic-regression.html#cb491-1" aria-hidden="true" tabindex="-1"></a>the_odds <span class="ot">&lt;-</span> <span class="fu">mean</span>(dat<span class="sc">$</span>lfp_yes) <span class="sc">/</span> (<span class="dv">1</span><span class="sc">-</span><span class="fu">mean</span>(dat<span class="sc">$</span>lfp_yes))</span>
<span id="cb491-2"><a href="logistic-regression.html#cb491-2" aria-hidden="true" tabindex="-1"></a>the_odds</span></code></pre></div>
<pre><code>## [1] 1.316923</code></pre>
<p>Now the log-odds:</p>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb493-1"><a href="logistic-regression.html#cb493-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(the_odds)</span></code></pre></div>
<pre><code>## [1] 0.275298</code></pre>
<p>Back to the model coefficient:</p>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb495-1"><a href="logistic-regression.html#cb495-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_intercept)</span></code></pre></div>
<pre><code>## (Intercept) 
##    0.275298</code></pre>
<p>HURRAH!</p>
<p>We could also go in reverse from the intercept. The function <code>exp(x)</code> calculates <span class="math inline">\(e^x\)</span> which is the inverse of <span class="math inline">\(\log_e\)</span>. This gives us the odds again:</p>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb497-1"><a href="logistic-regression.html#cb497-1" aria-hidden="true" tabindex="-1"></a>the_odds_again <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">coef</span>(mod_intercept))</span>
<span id="cb497-2"><a href="logistic-regression.html#cb497-2" aria-hidden="true" tabindex="-1"></a>the_odds_again</span></code></pre></div>
<pre><code>## (Intercept) 
##    1.316923</code></pre>
<p>Now to get the probability:</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb499-1"><a href="logistic-regression.html#cb499-1" aria-hidden="true" tabindex="-1"></a>the_odds_again <span class="sc">/</span> (<span class="dv">1</span><span class="sc">+</span>the_odds_again)</span></code></pre></div>
<pre><code>## (Intercept) 
##   0.5683931</code></pre>
<p><span class="math display">\[
\mathit{HURRAH}^\mathit{HURRAH}!
\]</span></p>
<p>Now we have got the hang of intercept-only models, onto slopes…</p>
</div>
<div id="interpret-slopes" class="section level2" number="8.11">
<h2><span class="header-section-number">8.11</span> Interpreting model slopes</h2>
<p>Look again at the graph:</p>
<p><img src="R-notes_files/figure-html/age-work-graph-1.png" width="672" /></p>
<p>Our hindsight hypothesis (having looked at the picture) – not a good way to do science, but fine for pedagogy – is that the number of children aged 5 or under will predict labour-force participation, but the number aged 6 or over will be irrelevant.</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb501-1"><a href="logistic-regression.html#cb501-1" aria-hidden="true" tabindex="-1"></a>mod_children <span class="ot">&lt;-</span> <span class="fu">glm</span>(lfp_yes <span class="sc">~</span> k5 <span class="sc">+</span> k618,</span>
<span id="cb501-2"><a href="logistic-regression.html#cb501-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">data =</span> dat,</span>
<span id="cb501-3"><a href="logistic-regression.html#cb501-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">family =</span> binomial)</span>
<span id="cb501-4"><a href="logistic-regression.html#cb501-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_children)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = lfp_yes ~ k5 + k618, family = binomial, data = dat)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.4566  -1.3712   0.9634   0.9953   1.7617  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.44479    0.11106   4.005 6.20e-05 ***
## k5          -0.87926    0.15817  -5.559 2.71e-08 ***
## k618         0.02730    0.05767   0.473    0.636    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1029.75  on 752  degrees of freedom
## Residual deviance:  994.53  on 750  degrees of freedom
## AIC: 1000.5
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>And indeed that is what we get. But how should we interpret those coefficients? Here is a suite of options. Any one of these would and has been publishable (see if you can spot them in the literature), but they are not equally interpretable.</p>
<div id="interpret-on-the-log-odds-scale" class="section level3 tabset" number="8.11.1">
<h3><span class="header-section-number">8.11.1</span> Interpret on the log-odds scale</h3>
<p>This summary is a linear model on the log-odds (i.e., logit) scale. So we can interpret as before, just always ensuring we remember that the outcome units are log-odds rather than probabilities.</p>
<div id="activity-29" class="section level4" number="8.11.1.1">
<h4><span class="header-section-number">8.11.1.1</span> Activity</h4>
<p>Have a go at interpreting the intercept and slopes, focussing on the direction of effects and whether they are statistically significant.</p>
</div>
<div id="answer-31" class="section level4" number="8.11.1.2">
<h4><span class="header-section-number">8.11.1.2</span> Answer</h4>
<p>The intercept is actually interpretable (for a change!). This gives the log-odds of being in work when a family has zero children: 0.44.</p>
<p>For every extra child aged 0-5, the log odds of being in work decrease by 0.88, <span class="math inline">\(z = -5.6\)</span>, <span class="math inline">\(p &lt; .001\)</span>.</p>
<p>There is no statistically significant effect for children aged 6 or over; slope = 0.03, <span class="math inline">\(z = 0.5\)</span>, <span class="math inline">\(p = 0.64\)</span>.</p>
</div>
</div>
<div id="interpret-using-the-divide-by-4-approximation" class="section level3 tabset" number="8.11.2">
<h3><span class="header-section-number">8.11.2</span> Interpret using the “divide-by-4” approximation</h3>
<p>Two of my favourite statisticians, Andrew Gelman and Jennifer Hill (2007, p. 82), provide a handy approximation for transforming slopes on the log-odds scale to changes in probability:</p>
<blockquote>
<p>“As a rule of convenience, we can take logistic regression coefficients (other than the constant term) and divide them by 4 to get an upper bound of the predictive difference corresponding to a unit difference in x. This upper bound is a reasonable approximation near the midpoint of the logistic curve, where probabilities are close to 0.5.”</p>
</blockquote>
<p>(The constant term is another word for the intercept.)</p>
<p>Here is the rule in a picture:</p>
<p><img src="R-notes_files/figure-html/unnamed-chunk-338-1.png" width="672" /></p>
<p>Where the the dashed purple line overlaps the curve, the probability <span class="math inline">\(p = 0.5 + \frac{\mathit{logit}}{4}\)</span>.</p>
<div id="activity-30" class="section level4" number="8.11.2.1">
<h4><span class="header-section-number">8.11.2.1</span> Activity</h4>
<p>Can you decode that paragraph from Gelman and Hill and use it to interpret the coefficients?</p>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb503-1"><a href="logistic-regression.html#cb503-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_children)</span></code></pre></div>
<pre><code>## (Intercept)          k5        k618 
##  0.44478849 -0.87925889  0.02729833</code></pre>
</div>
<div id="answer-32" class="section level4" number="8.11.2.2">
<h4><span class="header-section-number">8.11.2.2</span> Answer</h4>
<p>We can use the coefficients:</p>
<div class="sourceCode" id="cb505"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb505-1"><a href="logistic-regression.html#cb505-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_children)</span></code></pre></div>
<pre><code>## (Intercept)          k5        k618 
##  0.44478849 -0.87925889  0.02729833</code></pre>
<p>Drop the intercept (or you could just do so by not looking at it!):</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="logistic-regression.html#cb507-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_children)[<span class="sc">-</span><span class="dv">1</span>]</span></code></pre></div>
<pre><code>##          k5        k618 
## -0.87925889  0.02729833</code></pre>
<p>Divide by 4 and round (again, you could do this in other ways):</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="logistic-regression.html#cb509-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">coef</span>(mod_children)[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">/</span> <span class="dv">4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb509-2"><a href="logistic-regression.html#cb509-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(<span class="dv">2</span>)</span></code></pre></div>
<pre><code>##    k5  k618 
## -0.22  0.01</code></pre>
<p>For every extra child aged 5 or under, the probability of being work in decreases by (at most) 0.22.</p>
<p>The effect for children aged 6-18 was not statistically significant; moreover, the sample estimate is minuscule: every extra child adds 0.01 to the probability of being in work.</p>
</div>
</div>
<div id="interpret-using-odds" class="section level3" number="8.11.3">
<h3><span class="header-section-number">8.11.3</span> Interpret using odds</h3>
<p>There is an easy way to transform the predictors so that interpretation are on the odds scale, which are more interpretable than log-odds. Let’s explore why it works – skip to the <a href="logistic-regression.html#exp-meaning">So What?</a> section on a first read if you wish.</p>
<div id="some-arithmetic" class="section level4" number="8.11.3.1">
<h4><span class="header-section-number">8.11.3.1</span> Some arithmetic</h4>
<p>Here is the model formula again:</p>
<p><span class="math display">\[
\log_e\frac{p}{1-p}= \beta_0 + \beta_1 x_1 + \beta_1x_2 + \cdots + \beta_n x_n
\]</span></p>
<p>The left hand side gives the log odds and the right hand side is the linear formula we know and love from linear regression.</p>
<p>If we exponentiate both sides, this removes the log on the left and, er, complicates the right:</p>
<p><span class="math display">\[
\frac{p}{1-p}= e^{\beta_0 + \beta_1 x_1 + \beta_1x_2 + \cdots + \beta_n x_n}
\]</span></p>
<p>The left hand size now gives the odds. We can simplify the right to:</p>
<p><span class="math display">\[
\frac{p}{1-p}= e^{\beta_0} \times e^{\beta_1 x_1} \times e^{\beta_1 x_2} \times \cdots \times e^{\beta_n x_n}
\]</span>
since <span class="math inline">\(b^{x+y} = b^x b^y\)</span>. Note how all the additions have become multiplications.</p>
<p>Since <span class="math inline">\(b^{xy} = (b^x)^y\)</span> we can separate out the exponentiated slopes, which is useful because it is very easy to get these from a <code>glm</code> model summary (by <code>exp</code>ing the slopes).</p>
<p><span class="math display">\[
\frac{p}{1-p}= e^{\beta_0} \times (e^{\beta_1})^{x_1} \times (e^{\beta_2})^{x_2} \times \cdots \times (e^{\beta_n})^{x_n}
\]</span></p>
<p>This is much easier to read if we rewrite <span class="math inline">\(e^x\)</span> as <span class="math inline">\(\exp({x})\)</span>:</p>
<p><span class="math display">\[
\frac{p}{1-p}= \exp({\beta_0}) \times \exp({\beta_1})^{x_1} \times \exp({\beta_1})^{x_2} \times \cdots \times \exp({\beta_n})^{x_n}
\]</span></p>
</div>
<div id="exp-meaning" class="section level4" number="8.11.3.2">
<h4><span class="header-section-number">8.11.3.2</span> What does this mean? (Or: so what?)</h4>
<p>Here are the coefficients from our model predicting being in paid work from number of children:</p>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb511-1"><a href="logistic-regression.html#cb511-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_children)</span></code></pre></div>
<pre><code>## (Intercept)          k5        k618 
##  0.44478849 -0.87925889  0.02729833</code></pre>
<p>We can exponentiate (and round) them to:</p>
<div class="sourceCode" id="cb513"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb513-1"><a href="logistic-regression.html#cb513-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">coef</span>(mod_children)) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## (Intercept)          k5        k618 
##        1.56        0.42        1.03</code></pre>
<p>The coefficients for the slopes are called <strong>odds ratios</strong>.</p>
<p>Slot them back into the formula:</p>
<p><span class="math display">\[
\frac{p}{1-p}= 1.56 \times 0.42^{\mathtt{k5}} \times 1.03^{\mathtt{k618}}
\]</span></p>
<p>This gives us an interpretation of the (exponentiated) coefficients in terms of odds.</p>
<p>For every increase in <code>k5</code> (children aged 0 to 5) by one child, the odds of being in work multiply by 0.42; in other words they are <span class="math inline">\(100(1 - 0.42) = 58\%\)</span> lower.</p>
<p>Let’s try plugging some numbers in, first with no children:</p>
<p><span class="math display">\[
\begin{array}{rcl}
\frac{p}{1-p} &amp; = &amp;  1.56 \times 0.42^{0} \times 1.03^{0}\\
              &amp; = &amp;  1.56 \times 1 \times 1  \\   
              &amp; = &amp;  1.56  
\end{array}
\]</span></p>
<p>So the odds of being in work if you have no children are 1.56 – i.e., the same as the exponentiated intercept.</p>
<p>Let’s try one child aged 0 to 5 and no children aged 6 or over:
<span class="math display">\[
\begin{array}{rcl}
\frac{p}{1-p} &amp; = &amp;  1.56 \times 0.42^{1} \times 1.03^{0}\\
              &amp; = &amp;  1.56 \times 0.42 \times 1  \\   
              &amp; = &amp;  0.66  
\end{array}
\]</span></p>
<p>And two children aged 0 to 5, again with no children aged 6 or over:</p>
<p><span class="math display">\[
\begin{array}{rcl}
\frac{p}{1-p} &amp; = &amp;  1.56 \times 0.42^{2} \times 1.03^{0}\\
              &amp; = &amp;  1.56 \times 0.18 \times 1  \\   
              &amp; = &amp;  0.28  
\end{array}
\]</span></p>
</div>
</div>
<div id="interpret-using-predicted-probabilities" class="section level3" number="8.11.4">
<h3><span class="header-section-number">8.11.4</span> Interpret using predicted probabilities</h3>
<p>This is probably my favourite way to get to grips with how a model works and R does all the hard work for us. The idea is simply to ask the model for predicted probabilities for a range of inputs, chosen to help you and readers see how the outcome variable is related to the predictors.</p>
<p>There are two ways to do it in R. The second is easier (and you would be forgiven for <a href="logistic-regression.html#easierpredictions">trying it first</a>) but the first explains what’s going on.</p>
<div id="using-a-customs-predictions-table" class="section level4" number="8.11.4.1">
<h4><span class="header-section-number">8.11.4.1</span> Using a customs predictions table</h4>
<p>The recipe is as follows. First, generate a data frame with values for predictors for which you would like predictions. This is a data frame with one column for each variable in the model.</p>
<p>The <code>expand.grid</code> command is handy for this as it generates all combinations of the values you provide.</p>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb515-1"><a href="logistic-regression.html#cb515-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">k5   =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">3</span>,</span>
<span id="cb515-2"><a href="logistic-regression.html#cb515-2" aria-hidden="true" tabindex="-1"></a>                           <span class="at">k618 =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">5</span>))</span>
<span id="cb515-3"><a href="logistic-regression.html#cb515-3" aria-hidden="true" tabindex="-1"></a>predictions</span></code></pre></div>
<pre><code>##   k5 k618
## 1  0    0
## 2  1    0
## 3  2    0
## 4  3    0
## 5  0    5
## 6  1    5
## 7  2    5
## 8  3    5</code></pre>
<p>Recall that <code>k5</code> was “statistically significant” but <code>k618</code> not, so I have chosen a range of values for <code>k5</code> which show the association and also two extremes for <code>k618</code>.</p>
<p>Now use R’s <code>predict</code> command, passing this predictions table into its <code>newdat</code> parameter. We can get the predictions on the log-odds scale or (more useful) as probabilities. For the latter, use the option <code>type = "response"</code>.</p>
<p>I generally save the result onto the predictions data frame:</p>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb517-1"><a href="logistic-regression.html#cb517-1" aria-hidden="true" tabindex="-1"></a>predictions<span class="sc">$</span>lfp_logodds <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod_children, <span class="co"># the model</span></span>
<span id="cb517-2"><a href="logistic-regression.html#cb517-2" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">newdata =</span> predictions)</span>
<span id="cb517-3"><a href="logistic-regression.html#cb517-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb517-4"><a href="logistic-regression.html#cb517-4" aria-hidden="true" tabindex="-1"></a>predictions<span class="sc">$</span>lfp_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod_children,</span>
<span id="cb517-5"><a href="logistic-regression.html#cb517-5" aria-hidden="true" tabindex="-1"></a>                                <span class="at">newdata =</span> predictions,</span>
<span id="cb517-6"><a href="logistic-regression.html#cb517-6" aria-hidden="true" tabindex="-1"></a>                                <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<p>I will also add on the odds ratios, for completeness:</p>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="logistic-regression.html#cb518-1" aria-hidden="true" tabindex="-1"></a>predictions<span class="sc">$</span>lfp_odds <span class="ot">&lt;-</span> <span class="fu">exp</span>(predictions<span class="sc">$</span>lfp_logodds)</span></code></pre></div>
<p>Have a look (I’m piping them through <code>kabel</code> from the <code>knitr</code> package to change the number of decimal places):</p>
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb519-1"><a href="logistic-regression.html#cb519-1" aria-hidden="true" tabindex="-1"></a>predictions  <span class="sc">%&gt;%</span></span>
<span id="cb519-2"><a href="logistic-regression.html#cb519-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">k5</th>
<th align="right">k618</th>
<th align="right">lfp_logodds</th>
<th align="right">lfp_prob</th>
<th align="right">lfp_odds</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.44</td>
<td align="right">0.61</td>
<td align="right">1.56</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">0</td>
<td align="right">-0.43</td>
<td align="right">0.39</td>
<td align="right">0.65</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">0</td>
<td align="right">-1.31</td>
<td align="right">0.21</td>
<td align="right">0.27</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">0</td>
<td align="right">-2.19</td>
<td align="right">0.10</td>
<td align="right">0.11</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="right">5</td>
<td align="right">0.58</td>
<td align="right">0.64</td>
<td align="right">1.79</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">5</td>
<td align="right">-0.30</td>
<td align="right">0.43</td>
<td align="right">0.74</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">5</td>
<td align="right">-1.18</td>
<td align="right">0.24</td>
<td align="right">0.31</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">5</td>
<td align="right">-2.06</td>
<td align="right">0.11</td>
<td align="right">0.13</td>
</tr>
</tbody>
</table>
<p>The challenge is to pick values for the predictors which illustrate how the model works. You could then plot these using <code>ggplot</code>.</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb520-1"><a href="logistic-regression.html#cb520-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="sc">%&gt;%</span></span>
<span id="cb520-2"><a href="logistic-regression.html#cb520-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> k5,</span>
<span id="cb520-3"><a href="logistic-regression.html#cb520-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> lfp_prob, </span>
<span id="cb520-4"><a href="logistic-regression.html#cb520-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">colour =</span> <span class="fu">factor</span>(k618))) <span class="sc">+</span></span>
<span id="cb520-5"><a href="logistic-regression.html#cb520-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb520-6"><a href="logistic-regression.html#cb520-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb520-7"><a href="logistic-regression.html#cb520-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Number of children aged 0 to 5&quot;</span>,</span>
<span id="cb520-8"><a href="logistic-regression.html#cb520-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Probability of being in work&quot;</span>,</span>
<span id="cb520-9"><a href="logistic-regression.html#cb520-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">colour =</span> <span class="st">&quot;Children 6-18&quot;</span>) <span class="sc">+</span></span>
<span id="cb520-10"><a href="logistic-regression.html#cb520-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-349-1.png" width="672" /></p>
<p>By the way, predictions work for linear models fitted using <code>lm</code> too and can be particularly handy for making sense of interactions or other non-linear effects.</p>
</div>
<div id="easierpredictions" class="section level4" number="8.11.4.2">
<h4><span class="header-section-number">8.11.4.2</span> Use ggeffects</h4>
<p>Every few months someone creates a helpful R package for creating or understanding models. The <code>ggeffects</code> package is tear-jerkingly beautiful. See Lüdecke (2018) for more information. There are also helpful examples on the <a href="https://strengejacke.github.io/ggeffects/">package webpage</a>.</p>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb521-1"><a href="logistic-regression.html#cb521-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggeffects)</span></code></pre></div>
<p>The command for making predictions is called <code>ggpredict</code> and wants a model and at least one variable name. It can generate predictions for up to four variables whilst holding the others at some constant.</p>
<p>Let’s start with one, <code>k5</code>.</p>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="logistic-regression.html#cb522-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpredict</span>(mod_children, <span class="at">terms =</span> <span class="st">&quot;k5&quot;</span>)</span></code></pre></div>
<pre><code>## 
## # Predicted probabilities of lfp_yes
## # x = k5
## 
## x | Predicted |   SE |       95% CI
## -----------------------------------
## 0 |      0.62 | 0.08 | [0.58, 0.65]
## 1 |      0.40 | 0.15 | [0.33, 0.47]
## 2 |      0.22 | 0.29 | [0.13, 0.33]
## 3 |      0.10 | 0.45 | [0.05, 0.22]
## 
## Adjusted for:
## * k618 = 1.00</code></pre>
<pre><code>## Standard errors are on the link-scale (untransformed).</code></pre>
<p>It tries to guess sensible values to hold other predictions at. Here it has held <code>k618</code> at 1.</p>
<p>The package also comes with a <code>plot</code> function which automatically gives you a <code>ggplot</code> object.</p>
<div class="sourceCode" id="cb525"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb525-1"><a href="logistic-regression.html#cb525-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpredict</span>(mod_children, <span class="at">terms =</span> <span class="fu">c</span>(<span class="st">&quot;k5&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb525-2"><a href="logistic-regression.html#cb525-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>()</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-352-1.png" width="672" /></p>
<p>The grey area is a 95% confidence band.</p>
<p>You can then modify this plot as you would any other <code>ggplot</code> object:</p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="logistic-regression.html#cb526-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpredict</span>(mod_children, <span class="at">terms =</span> <span class="fu">c</span>(<span class="st">&quot;k5&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb526-2"><a href="logistic-regression.html#cb526-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>() <span class="sc">+</span></span>
<span id="cb526-3"><a href="logistic-regression.html#cb526-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb526-4"><a href="logistic-regression.html#cb526-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Number of children aged 0 to 5&quot;</span>) <span class="sc">+</span></span>
<span id="cb526-5"><a href="logistic-regression.html#cb526-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Probability of being in the labour force&quot;</span>) <span class="sc">+</span></span>
<span id="cb526-6"><a href="logistic-regression.html#cb526-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="cn">NULL</span>) <span class="sc">+</span></span>
<span id="cb526-7"><a href="logistic-regression.html#cb526-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-353-1.png" width="672" /></p>
<p>Before publication (or module assignment), be sure to explain in your Figure captions what exactly a graph shows, i.e., in this case that the number of children ages 6 to 18 has been held at 1.</p>
</div>
</div>
</div>
<div id="diagnostics" class="section level2" number="8.12">
<h2><span class="header-section-number">8.12</span> Diagnostics</h2>
<p>Good news: we will use the same diagnostic tools as for linear regression. Actually (slightly) fewer will now apply.</p>
<p>Load the <code>car</code> package:</p>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb527-1"><a href="logistic-regression.html#cb527-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span></code></pre></div>
<div id="check-the-residual-distribution" class="section level3" number="8.12.1">
<h3><span class="header-section-number">8.12.1</span> Check the residual distribution</h3>
<p>You can check for outlying residuals as before:</p>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb528-1"><a href="logistic-regression.html#cb528-1" aria-hidden="true" tabindex="-1"></a><span class="fu">outlierTest</span>(mod_children)</span></code></pre></div>
<pre><code>## No Studentized residuals with Bonferroni p &lt; 0.05
## Largest |rstudent|:
##    rstudent unadjusted p-value Bonferroni p
## 92 1.778802           0.075272           NA</code></pre>
<p>Do not check if the residuals are normally distributed – they will not be and that is fine in GLM land.</p>
</div>
<div id="check-that-the-residual-mean-is-constant" class="section level3" number="8.12.2">
<h3><span class="header-section-number">8.12.2</span> Check that the residual mean is constant</h3>
<p>The <code>residualPlots</code> works as before, except when you run it with default setting on this model and data it will complain that “all data are on boundary of neighbourhood, make span bigger.” The “span” refers to how much smoothing the smoother does!</p>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="logistic-regression.html#cb530-1" aria-hidden="true" tabindex="-1"></a><span class="fu">residualPlots</span>(mod_children,</span>
<span id="cb530-2"><a href="logistic-regression.html#cb530-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">tests =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>By default the span of the smoother is <code>2/3</code>. For this model and data, setting it to 1 works fine:</p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb531-1"><a href="logistic-regression.html#cb531-1" aria-hidden="true" tabindex="-1"></a><span class="fu">residualPlots</span>(mod_children,</span>
<span id="cb531-2"><a href="logistic-regression.html#cb531-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">tests =</span> <span class="cn">FALSE</span>,</span>
<span id="cb531-3"><a href="logistic-regression.html#cb531-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">smooth =</span> <span class="fu">list</span>(<span class="at">span =</span> <span class="dv">1</span>))</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-357-1.png" width="576" /></p>
<p>The patterns in the data points you see here are due to the outcome variable only taking on a 0 or a 1. This is to be expected. Focus on the magenta curves and ensure that they aren’t curves (if you see what I mean…?): they should be straight lines along zero. And indeed here they are.</p>
<p>The variance does <em>not</em> need to be constant for GLMs other than the normal/Gaussian model.</p>
</div>
<div id="linearity-of-predictors" class="section level3" number="8.12.3">
<h3><span class="header-section-number">8.12.3</span> Linearity of predictors</h3>
<p>We can use <code>crPlots</code> again to obtain component-plus-residual plots.</p>
<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb532-1"><a href="logistic-regression.html#cb532-1" aria-hidden="true" tabindex="-1"></a><span class="fu">crPlots</span>(mod_children, <span class="at">smooth =</span> <span class="fu">list</span>(<span class="at">span =</span> <span class="dv">1</span>))</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-358-1.png" width="672" /></p>
<p>These too are fine – no obvious curves, though potentially something worth exploring towards the upper end of <code>k618</code> where there isn’t much data (i.e., few families over 6 children). Again I had to fiddle with the <code>span</code> parameter to stop the smoother complaining.</p>
</div>
<div id="influence" class="section level3" number="8.12.4">
<h3><span class="header-section-number">8.12.4</span> Influence</h3>
<p>Again everything we covered in the previous session applies here. Here’s a quick way to look at potentially influential points:</p>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb533-1"><a href="logistic-regression.html#cb533-1" aria-hidden="true" tabindex="-1"></a><span class="fu">influence.measures</span>(mod_children) <span class="sc">%&gt;%</span></span>
<span id="cb533-2"><a href="logistic-regression.html#cb533-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## Potentially influential observations of
##   glm(formula = lfp_yes ~ k5 + k618, family = binomial, data = dat) :
## 
##     dfb.1_ dfb.k5 dfb.k618 dffit   cov.r   cook.d hat    
## 18  -0.03  -0.02   0.09     0.09    1.01_*  0.00   0.01_*
## 53  -0.08  -0.03   0.15     0.15    1.04_*  0.01   0.04_*
## 74  -0.08   0.17   0.08     0.20_*  1.01_*  0.02   0.02_*
## 79  -0.03   0.18   0.01     0.18    1.01    0.02   0.01_*
## 92   0.02   0.18  -0.07     0.20_*  1.01    0.02   0.02_*
## 111  0.02   0.18  -0.07     0.20_*  1.01    0.02   0.02_*
## 186 -0.07   0.06   0.11     0.14    1.01_*  0.01   0.01_*
## 217 -0.07   0.06   0.11     0.14    1.01_*  0.01   0.01_*
## 252 -0.07   0.06   0.11     0.14    1.01_*  0.01   0.01_*
## 327 -0.03  -0.02   0.09     0.09    1.01_*  0.00   0.01_*
## 352  0.00   0.18  -0.03     0.19    1.01    0.02   0.01_*
## 371 -0.03  -0.02   0.09     0.09    1.01_*  0.00   0.01_*
## 400 -0.03   0.18   0.01     0.18    1.01    0.02   0.01_*
## 423  0.02   0.18  -0.07     0.20_*  1.01    0.02   0.02_*
## 424 -0.03  -0.02   0.09     0.09    1.01_*  0.00   0.01_*
## 430 -0.01  -0.07   0.03    -0.08    1.02_*  0.00   0.02_*
## 434  0.05   0.03  -0.13    -0.14    1.01    0.01   0.01_*
## 447  0.02  -0.07  -0.02    -0.08    1.02_*  0.00   0.02_*
## 450 -0.01  -0.07   0.03    -0.08    1.02_*  0.00   0.02_*
## 459 -0.01  -0.07   0.03    -0.08    1.02_*  0.00   0.02_*
## 462  0.01  -0.07   0.00    -0.08    1.02_*  0.00   0.01_*
## 463  0.02  -0.07  -0.02    -0.08    1.02_*  0.00   0.02_*
## 466 -0.01  -0.07   0.03    -0.08    1.02_*  0.00   0.02_*
## 482  0.05   0.03  -0.13    -0.14    1.01    0.01   0.01_*
## 483  0.00  -0.07   0.01    -0.07    1.02_*  0.00   0.01_*
## 484  0.00  -0.06   0.01    -0.06    1.02_*  0.00   0.02_*
## 499  0.05   0.03  -0.13    -0.14    1.01    0.01   0.01_*
## 509 -0.01  -0.07   0.03    -0.08    1.02_*  0.00   0.02_*
## 528 -0.01  -0.07   0.03    -0.08    1.02_*  0.00   0.02_*
## 553  0.01  -0.07   0.00    -0.08    1.02_*  0.00   0.01_*
## 574 -0.01  -0.07   0.03    -0.08    1.02_*  0.00   0.02_*
## 580  0.00  -0.07   0.01    -0.07    1.02_*  0.00   0.01_*
## 585  0.00  -0.07   0.01    -0.07    1.02_*  0.00   0.01_*
## 595  0.05   0.03  -0.13    -0.14    1.01    0.01   0.01_*
## 605  0.02  -0.06  -0.01    -0.06    1.02_*  0.00   0.02_*
## 617  0.00  -0.07   0.01    -0.07    1.02_*  0.00   0.01_*
## 641  0.01  -0.07   0.00    -0.08    1.02_*  0.00   0.01_*
## 678  0.05   0.03  -0.13    -0.14    1.01    0.01   0.01_*
## 715  0.00  -0.05   0.02    -0.06    1.02_*  0.00   0.02_*
## 720  0.10   0.04  -0.20    -0.21_*  1.02_*  0.02   0.03_*
## 732 -0.01  -0.07   0.03    -0.08    1.02_*  0.00   0.02_*
## 746  0.05  -0.07  -0.07    -0.11    1.03_*  0.00   0.03_*
## 750  0.02  -0.07  -0.02    -0.08    1.02_*  0.00   0.02_*</code></pre>
<p>We could also look at (my favourite) the DFBETA plots:</p>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb535-1"><a href="logistic-regression.html#cb535-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dfbetaPlots</span>(mod_children)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-360-1.png" width="672" /></p>
<p>The numbers are minuscule, relative to the model slopes, so nothing to worry about. I am curious about the largest DFBETA for <code>k618</code>, though. The raw descriptives showed one person with eight children aged 6 to 18 who was in work. Is the slope being ever so slightly dragged up by her data?</p>
<div class="sourceCode" id="cb536"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb536-1"><a href="logistic-regression.html#cb536-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dfbeta</span>(mod_children) <span class="sc">%&gt;%</span></span>
<span id="cb536-2"><a href="logistic-regression.html#cb536-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb536-3"><a href="logistic-regression.html#cb536-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(k618 <span class="sc">&gt;</span> .<span class="dv">009</span>)</span></code></pre></div>
<pre><code>##     (Intercept)           k5        k618
## 53 -0.009795223 -0.005237558 0.009994706</code></pre>
<p>That’s row 53, so let’s <code>slice</code> the data to look:</p>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb538-1"><a href="logistic-regression.html#cb538-1" aria-hidden="true" tabindex="-1"></a>dat <span class="sc">%&gt;%</span></span>
<span id="cb538-2"><a href="logistic-regression.html#cb538-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">53</span>)</span></code></pre></div>
<pre><code>##   lfp lfp_yes k5 k618 age wc hc       lwg    inc
## 1 yes       1  0    8  37 no no 0.1625193 16.258</code></pre>
<p>Yes, this is the one person with 8 children! But it doesn’t matter since the dataset is so large and the DFBETA minuscule.</p>
</div>
<div id="multicolinearity" class="section level3" number="8.12.5">
<h3><span class="header-section-number">8.12.5</span> Multicolinearity</h3>
<p>Yep, you can still check the variance inflation factors (VIFs) and interpret as before!</p>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="logistic-regression.html#cb540-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(mod_children)</span></code></pre></div>
<pre><code>##       k5     k618 
## 1.010858 1.010858</code></pre>
<p>These are both close to 1 so all is good.</p>
<p>We could try adding multicollinearity, just to be sure that the VIFs work… Here I’m adding a new variable called <code>kids</code> which is the sum of <code>k5</code> and <code>k618</code>:</p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="logistic-regression.html#cb542-1" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> dat <span class="sc">%&gt;%</span></span>
<span id="cb542-2"><a href="logistic-regression.html#cb542-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">kids =</span> k5 <span class="sc">+</span> k618)</span></code></pre></div>
<p>Here’s a model with both <code>k618</code> and <code>kids</code> as predictors:</p>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb543-1"><a href="logistic-regression.html#cb543-1" aria-hidden="true" tabindex="-1"></a>high_vif_maybe <span class="ot">&lt;-</span> <span class="fu">glm</span>(lfp_yes <span class="sc">~</span> k618 <span class="sc">+</span> kids, </span>
<span id="cb543-2"><a href="logistic-regression.html#cb543-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data =</span> dat, <span class="at">family =</span> binomial)</span></code></pre></div>
<p>And here are the VIFs:</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="logistic-regression.html#cb544-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(high_vif_maybe)</span></code></pre></div>
<pre><code>##     k618     kids 
## 9.189766 9.189766</code></pre>
<p>They are high as you might expect, given how the <code>kids</code> variable was created.</p>
</div>
</div>
<div id="a-challenge" class="section level2 tabset" number="8.13">
<h2><span class="header-section-number">8.13</span> A challenge</h2>
<div id="activity-31" class="section level3" number="8.13.1">
<h3><span class="header-section-number">8.13.1</span> Activity</h3>
<p>There are several other variables in the dataset which you can now explore.</p>
<ol style="list-style-type: lower-alpha">
<li>Does a model with the following predictors added predict better than one with only the number of children?</li>
</ol>
<table>
<thead>
<tr class="header">
<th>Variable name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>age</code></td>
<td>in years.</td>
</tr>
<tr class="even">
<td><code>wc</code></td>
<td>wife’s college attendance (no/yes).</td>
</tr>
<tr class="odd">
<td><code>hc</code></td>
<td>husband’s college attendance (no/yes).</td>
</tr>
<tr class="even">
<td><code>inc</code></td>
<td>family income exclusive of wife’s income (in $1000s).</td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: lower-alpha">
<li>Interpret the coefficients, using a method of your choice</li>
<li>Try some diagnostics (this week you have some more creative freedom) – do you want to do anything as a result of what you find?</li>
</ol>
</div>
<div id="an-answer" class="section level3" number="8.13.2">
<h3><span class="header-section-number">8.13.2</span> (An) Answer</h3>
<p><strong>a. Does a model with the following predictors [list of predictors] added predict better than one with only the number of children?</strong></p>
<p>Here’s another way to add predictors to a previously fitted model; however, copy and paste works fine too!</p>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="logistic-regression.html#cb546-1" aria-hidden="true" tabindex="-1"></a>mod_more <span class="ot">&lt;-</span> <span class="fu">update</span>(mod_children,</span>
<span id="cb546-2"><a href="logistic-regression.html#cb546-2" aria-hidden="true" tabindex="-1"></a>                   . <span class="sc">~</span> . <span class="sc">+</span> age <span class="sc">+</span> wc <span class="sc">+</span> hc <span class="sc">+</span> inc)</span></code></pre></div>
<p>Does this more complex model explain the data better?</p>
<div class="sourceCode" id="cb547"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb547-1"><a href="logistic-regression.html#cb547-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod_children, mod_more, <span class="at">test =</span> <span class="st">&quot;Chi&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: lfp_yes ~ k5 + k618
## Model 2: lfp_yes ~ k5 + k618 + age + wc + hc + inc
##   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
## 1       750     994.53                          
## 2       746     922.27  4   72.259 7.568e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>For what it’s worth (we haven’t checked any model diagnostics yet, so this could be nonsense), yes, the model fits better, <span class="math inline">\(\chi^2(4) = 72.3\)</span>, <span class="math inline">\(p &lt; .001\)</span>.</p>
<p><strong>b. Interpret the coefficients, using a method of your choice</strong></p>
<p>I’m going to use two approaches. First the divide-by-four approach, using the original model summary to work out the direction of effects and whether they are statistically significant:</p>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="logistic-regression.html#cb549-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_more)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = lfp_yes ~ k5 + k618 + age + wc + hc + inc, family = binomial, 
##     data = dat)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.0971  -1.1138   0.6442   0.9980   2.1293  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.764814   0.626022   6.014 1.81e-09 ***
## k5          -1.470687   0.195576  -7.520 5.49e-14 ***
## k618        -0.087870   0.067298  -1.306    0.192    
## age         -0.062877   0.012655  -4.969 6.75e-07 ***
## wcyes        1.003779   0.222230   4.517 6.28e-06 ***
## hcyes        0.119029   0.204072   0.583    0.560    
## inc         -0.032105   0.008057  -3.985 6.76e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1029.75  on 752  degrees of freedom
## Residual deviance:  922.27  on 746  degrees of freedom
## AIC: 936.27
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<p>Here are the coefficients, for ease of reading:</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb551-1"><a href="logistic-regression.html#cb551-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">coef</span>(mod_more)[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">/</span> <span class="dv">4</span>) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">2</span>)</span></code></pre></div>
<pre><code>##    k5  k618   age wcyes hcyes   inc 
## -0.37 -0.02 -0.02  0.25  0.03 -0.01</code></pre>
<p>All statistically significant effects have p’s far below .05.</p>
<p>As before, the number of children aged 0 to 5 is negatively associated with the probability of being in work; each extra child reduces the probability by at most 0.37. There was no statistically significant effect for number of children aged 6 to 18.</p>
<p>The woman’s age was a statistically significant predictor; each extra year reduced the probability by 0.06.</p>
<p>Whether the woman had a college education was a statistically significant predictor and increased the probability of being in work by at most 0.25. There was no statistically significant effect for the husband’s college education.</p>
<p>Finally, family income, excluding the woman’s income, had a significant effect too. Each extra $1000 reduces the probability of her being in work by 0.01.</p>
<p>Here is a picture.</p>
<div class="sourceCode" id="cb553"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb553-1"><a href="logistic-regression.html#cb553-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpredict</span>(mod_more, <span class="at">terms =</span> <span class="fu">c</span>(<span class="st">&quot;k5&quot;</span>, <span class="st">&quot;wc&quot;</span>, <span class="st">&quot;age [30,45,60]&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb553-2"><a href="logistic-regression.html#cb553-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>() <span class="sc">+</span></span>
<span id="cb553-3"><a href="logistic-regression.html#cb553-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Number of children aged 0 to 5&quot;</span>) <span class="sc">+</span></span>
<span id="cb553-4"><a href="logistic-regression.html#cb553-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Probability of being in work&quot;</span>) <span class="sc">+</span></span>
<span id="cb553-5"><a href="logistic-regression.html#cb553-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="cn">NULL</span>, <span class="at">colour =</span> <span class="st">&quot;Woman attended college&quot;</span>) <span class="sc">+</span></span>
<span id="cb553-6"><a href="logistic-regression.html#cb553-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb553-7"><a href="logistic-regression.html#cb553-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_gray</span>() <span class="sc">+</span></span>
<span id="cb553-8"><a href="logistic-regression.html#cb553-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-371-1.png" width="576" /></p>
<p>Adjusted for: number of children aged 6 to 18 was fixed at 1, husband fixed at no college education, and income at the mean, $2013.</p>
<p>(Wasn’t that fantastically easy? Most of the code was just fiddling with the layout.)</p>
<p>How about income?</p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb554-1"><a href="logistic-regression.html#cb554-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpredict</span>(mod_more, <span class="at">terms =</span> <span class="fu">c</span>(<span class="st">&quot;inc&quot;</span>, <span class="st">&quot;wc&quot;</span>, <span class="st">&quot;k5&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb554-2"><a href="logistic-regression.html#cb554-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>() <span class="sc">+</span></span>
<span id="cb554-3"><a href="logistic-regression.html#cb554-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Family income exc. wife (in $1000s)&quot;</span>) <span class="sc">+</span></span>
<span id="cb554-4"><a href="logistic-regression.html#cb554-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Probability of being in work&quot;</span>) <span class="sc">+</span></span>
<span id="cb554-5"><a href="logistic-regression.html#cb554-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="cn">NULL</span>, <span class="at">colour =</span> <span class="st">&quot;Attended college&quot;</span>) <span class="sc">+</span></span>
<span id="cb554-6"><a href="logistic-regression.html#cb554-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb554-7"><a href="logistic-regression.html#cb554-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_gray</span>() <span class="sc">+</span></span>
<span id="cb554-8"><a href="logistic-regression.html#cb554-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-372-1.png" width="576" /></p>
<p>The effect of family income was sensitive to the number of children – more marked for lower numbers of children – highlighting why it is worth plotting model predictions.</p>
<p><strong>c. Try some diagnostics (this week you have some more creative freedom) – do you want to do anything as a result of what you find?</strong></p>
<p>I’m going to start with the VIFs.</p>
<div class="sourceCode" id="cb555"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb555-1"><a href="logistic-regression.html#cb555-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(mod_more)</span></code></pre></div>
<pre><code>##       k5     k618      age       wc       hc      inc 
## 1.396006 1.249884 1.650316 1.446317 1.552617 1.232176</code></pre>
<p>No obvious problems.</p>
<p>Residual plots show no obvious problems either:</p>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb557-1"><a href="logistic-regression.html#cb557-1" aria-hidden="true" tabindex="-1"></a><span class="fu">residualPlots</span>(mod_more,</span>
<span id="cb557-2"><a href="logistic-regression.html#cb557-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">tests =</span> F,</span>
<span id="cb557-3"><a href="logistic-regression.html#cb557-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">smooth =</span> <span class="fu">list</span>(<span class="at">span =</span> <span class="dv">1</span>))</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-374-1.png" width="768" /></p>
<p>The component + residual plots look beautifully linear:</p>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb558-1"><a href="logistic-regression.html#cb558-1" aria-hidden="true" tabindex="-1"></a><span class="fu">crPlots</span>(mod_more,<span class="at">smooth =</span> <span class="fu">list</span>(<span class="at">span =</span> .<span class="dv">977</span>))</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-375-1.png" width="768" /></p>
<p>How about the DFBETA values?</p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="logistic-regression.html#cb559-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dfbetaPlots</span>(mod_more)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-376-1.png" width="576" /></p>
<p>Maybe worth looking at the largest DFBETA values for <code>inc</code>?</p>
<div class="sourceCode" id="cb560"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb560-1"><a href="logistic-regression.html#cb560-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dfbeta</span>(mod_more) <span class="sc">%&gt;%</span></span>
<span id="cb560-2"><a href="logistic-regression.html#cb560-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb560-3"><a href="logistic-regression.html#cb560-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(inc <span class="sc">&gt;</span> <span class="fl">0.0015</span>)</span></code></pre></div>
<pre><code>##     (Intercept)           k5          k618           age        wcyes
## 104 -0.03229246 -0.002015986 -0.0005965456  2.067386e-05  0.007515251
## 119 -0.06117716  0.019764440  0.0039864127  1.382225e-04  0.002447020
## 386  0.01529085 -0.008335088 -0.0055467113 -1.037453e-03  0.005527216
## 402 -0.02443821  0.002537611 -0.0010025296 -3.206300e-06 -0.011153507
##            hcyes         inc
## 104 -0.007958268 0.001910912
## 119 -0.017951258 0.002801355
## 386 -0.011739797 0.002298775
## 402 -0.020029836 0.002007410</code></pre>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb562-1"><a href="logistic-regression.html#cb562-1" aria-hidden="true" tabindex="-1"></a>dat <span class="sc">%&gt;%</span></span>
<span id="cb562-2"><a href="logistic-regression.html#cb562-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="fu">c</span>(<span class="dv">104</span>,<span class="dv">119</span>,<span class="dv">386</span>,<span class="dv">402</span>))</span></code></pre></div>
<pre><code>##   lfp lfp_yes k5 k618 age  wc  hc      lwg   inc kids
## 1 yes       1  0    1  48 yes yes 1.654900 70.75    1
## 2 yes       1  1    3  38 yes yes 1.299283 91.00    4
## 3 yes       1  0    0  41 yes yes 1.948094 79.80    0
## 4 yes       1  0    1  48  no  no 1.341559 59.00    1</code></pre>
<p>They all have high family incomes, compared to the distribution…</p>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="logistic-regression.html#cb564-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(dat<span class="sc">$</span>inc)</span></code></pre></div>
<p><img src="R-notes_files/figure-html/unnamed-chunk-379-1.png" width="672" /></p>
<p>Also all these participants are in work, so they are dragging the coefficient for income slightly upwards. We could try removing them and fitting the model again.</p>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="logistic-regression.html#cb565-1" aria-hidden="true" tabindex="-1"></a>sliced_dat <span class="ot">&lt;-</span> dat <span class="sc">%&gt;%</span></span>
<span id="cb565-2"><a href="logistic-regression.html#cb565-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="sc">-</span><span class="fu">c</span>(<span class="dv">104</span>,<span class="dv">119</span>,<span class="dv">386</span>,<span class="dv">402</span>))</span>
<span id="cb565-3"><a href="logistic-regression.html#cb565-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb565-4"><a href="logistic-regression.html#cb565-4" aria-hidden="true" tabindex="-1"></a>mod_more_sliced <span class="ot">&lt;-</span> <span class="fu">glm</span>(lfp_yes <span class="sc">~</span> k5 <span class="sc">+</span> k618 <span class="sc">+</span></span>
<span id="cb565-5"><a href="logistic-regression.html#cb565-5" aria-hidden="true" tabindex="-1"></a>                         age <span class="sc">+</span> wc <span class="sc">+</span> hc <span class="sc">+</span> inc,</span>
<span id="cb565-6"><a href="logistic-regression.html#cb565-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">family =</span> binomial,</span>
<span id="cb565-7"><a href="logistic-regression.html#cb565-7" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data =</span> sliced_dat)</span>
<span id="cb565-8"><a href="logistic-regression.html#cb565-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_more_sliced)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = lfp_yes ~ k5 + k618 + age + wc + hc + inc, family = binomial, 
##     data = sliced_dat)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.0959  -1.1123   0.6371   0.9929   2.0528  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.913525   0.634438   6.168 6.89e-10 ***
## k5          -1.495603   0.198131  -7.549 4.40e-14 ***
## k618        -0.086207   0.067894  -1.270    0.204    
## age         -0.062075   0.012762  -4.864 1.15e-06 ***
## wcyes        1.003235   0.224009   4.479 7.52e-06 ***
## hcyes        0.192563   0.206951   0.930    0.352    
## inc         -0.043557   0.009046  -4.815 1.47e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1025.21  on 748  degrees of freedom
## Residual deviance:  909.38  on 742  degrees of freedom
## AIC: 923.38
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>The qualitative patterns are the same in terms of direction of effects and which are statistically significant. We could peek at the coefficients in more detail.</p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="logistic-regression.html#cb567-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="fu">coef</span>(mod_more), <span class="fu">coef</span>(mod_more_sliced)) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">2</span>)</span></code></pre></div>
<pre><code>##              [,1]  [,2]
## (Intercept)  3.76  3.91
## k5          -1.47 -1.50
## k618        -0.09 -0.09
## age         -0.06 -0.06
## wcyes        1.00  1.00
## hcyes        0.12  0.19
## inc         -0.03 -0.04</code></pre>
<p>Not a huge amount of difference and we have no reason to believe they are actually “outliers,” just relatively rare in the dataset, so best leave them in.</p>
<p>Whatever we had done, it’s important to show this “sensitivity analysis” so readers can decide for themselves which set of coefficients to use.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="categorical-predictors-and-interactions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="complex-surveys.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["R-notes.pdf", "R-notes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
