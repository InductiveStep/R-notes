[["complex-surveys.html", "Chapter 7 Complex surveys 7.1 Readings 7.2 The dataset 7.3 The components of a survey design 7.4 Describing the data 7.5 Fitting a GLM 7.6 Slopes 7.7 Diagnostics", " Chapter 7 Complex surveys (Work in progress!) By the end of this chapter you will know how to: Setup a survey object using complex survey information such as sampling weight and stratification variables. Use a tidyverse-esq approach for descriptive statistics. Fit a GLM (logistic). We will use the survey package and a wonderful tidyverse-style wrapper called srvyr. library(survey) library(srvyr) 7.1 Readings See srvyr compared to the survey package and Fox and Weisbergs online appendix, Fitting Regression Models to Data From Complex Surveys. The main reference for the model implemented by survey is by Lumley (2010). UCLA has a fab site with info too. 7.2 The dataset This chapters dataset is drawn from the 2011 Canadian National Election Study  taken from the carData package and described by the Fox and Weisberg appendix above. Download it here. There are 2231 observations on the following 9 variables: Variable name Description id Household ID number. province a factor with (alphabetical) levels AB, BC, MB, NB, NL, NS, ON, PE, QC, SK; the sample was stratified by province. population population of the respondents province, number over age 17. weight weight sample to size of population, taking into account unequal sampling probabilities by province and household size. gender a factor with levels Female, Male. abortion attitude toward abortion, a factor with levels No, Yes; answer to the question Should abortion be banned? importance importance of religion, a factor with (alphabetical) levels not, notvery, somewhat, very; answer to the question, In your life, would you say that religion is very important, somewhat important, not very important, or not important at all? education a factor with (alphabetical) levels bachelors (Bachelors degree), college (community college or technical school), higher (graduate degree), HS (high-school graduate), lessHS (less than high-school graduate), somePS (some post-secondary). urban place of residence, a factor with levels rural, urban. Read in the data. ces &lt;- read.csv(&quot;ces11.csv&quot;, stringsAsFactors = TRUE) head(ces) ## id province population weight gender abortion importance education urban ## 1 2851 BC 3267345 4287.85 Female No somewhat somePS urban ## 2 521 QC 5996930 9230.78 Male No not bachelors urban ## 3 2118 QC 5996930 6153.85 Male Yes somewhat college urban ## 4 1815 NL 406455 3430.00 Female No very somePS urban ## 5 1799 ON 9439960 8977.61 Male No not higher rural ## 6 1103 ON 9439960 8977.61 Female No not higher urban Im setting stringsAsFactors to TRUE so that the variables which are obviously factors are setup accordingly (R used to this by default; sometimes it had irritating side-effects). 7.3 The components of a survey design The key parts of the dataset which describe the survey design are as follows: ces %&gt;% select(id, province, population, weight) %&gt;% head(6) ## id province population weight ## 1 2851 BC 3267345 4287.85 ## 2 521 QC 5996930 9230.78 ## 3 2118 QC 5996930 6153.85 ## 4 1815 NL 406455 3430.00 ## 5 1799 ON 9439960 8977.61 ## 6 1103 ON 9439960 8977.61 id is a unique identifier for each individual, which is particularly important when there is more than one data point per person, e.g., for multilevel modelling (not in this dataset). province the data were stratified by province  random sampling by landline numbers was done within province population provides the population by province weight is the sampling weight, in this dataset calculated based on differences in province population, the study sample size therein, and household size Here is how to setup a survey object using srvyr: ces_s &lt;- ces %&gt;% as_survey(ids = id, strata = province, fpc = population, weights = weight) 7.4 Describing the data We will sometimes want to compare weighted and unweighted analyses. Here is a warmup activity to show how using the tidyverse. 7.4.1 Activity use the ces data frame and tidyverse to calculate the number of people who think abortion should be banned do the same again, but this time use the ces_s survey object created above  what do you notice? compare the proportions saying yes by group Hint: you will want to use group_by. Another hint: to count, use the function n. The version for survey objects is called survey_total. 7.4.2 Answer a. use the ces data frame and tidyverse to calculate the number of people who think abortion should be banned ces %&gt;% group_by(abortion) %&gt;% summarise(n = n()) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 2 x 2 ## abortion n ## &lt;fct&gt; &lt;int&gt; ## 1 No 1818 ## 2 Yes 413 b. do the same again, but this time use the ces_s survey object created above  what do you notice? ces_s %&gt;% group_by(abortion) %&gt;% summarise(n = survey_total()) ## # A tibble: 2 x 3 ## abortion n n_se ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 No 13059520. 196984. ## 2 Yes 2964018. 162360. The counts are much bigger than the number of rows in the dataset due to the sampling weights. c. compare the proportions saying yes by group One way to do this is by copy and paste! Unweighted: prop_unweighted &lt;- 413 / (413 + 1818) prop_unweighted ## [1] 0.1851188 Weighted: prop_weighted &lt;- 2964018 / (2964018 + 13059520) prop_weighted ## [1] 0.184979 The unweighted proportion of yes is only a little different in this case: 0.1851188 (unweighted) v 0.184979 (weighted), though that represents a population difference of over 2,000 people. Heres how to answer the questions in one go: ces_s %&gt;% group_by(abortion) %&gt;% summarise(n_raw = unweighted(n()), n_weighted = survey_total()) %&gt;% mutate(prop_raw = n_raw / sum(n_raw), prop_weighted = n_weighted / sum(n_weighted)) %&gt;% select(-n_weighted_se) ## # A tibble: 2 x 5 ## abortion n_raw n_weighted prop_raw prop_weighted ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 No 1818 13059520. 0.815 0.815 ## 2 Yes 413 2964018. 0.185 0.185 7.5 Fitting a GLM The survey package makes this very easy. There is a command called svyglm which is identical to glm except it has parameter called design instead if data. See ?svyglm 7.5.1 Activity mutate the survey object to add a binary variable called againstAbortion which is 1 if the participant is against abortion and 0 if not. fit an intercept-only logistic regression model without using weights (you can use as_tibble to get the raw data frame hidden within the survey object). Do the same again, this time using the survey structure. compare the predicted proportions with the raw proportions we calculated earlier 7.5.2 Answer a. mutate the survey object to add a binary variable called againstAbortion which is 1 if the participant is against abortion and 0 if not. ces_s &lt;- ces_s %&gt;% mutate(againstAbortion = as.numeric(ces$abortion == &quot;Yes&quot;)) b. fit an intercept-only logistic regression model without using weights (you can use as_tibble to get the raw data frame hidden within the survey object). m0 &lt;- glm(againstAbortion ~ 1, data = as_tibble(ces_s), family = binomial) summary(m0) ## ## Call: ## glm(formula = againstAbortion ~ 1, family = binomial, data = as_tibble(ces_s)) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.6399 -0.6399 -0.6399 -0.6399 1.8367 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.48204 0.05451 -27.19 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2137.6 on 2230 degrees of freedom ## Residual deviance: 2137.6 on 2230 degrees of freedom ## AIC: 2139.6 ## ## Number of Fisher Scoring iterations: 4 c. Do the same again, this time using the survey structure. sm0 &lt;- svyglm(againstAbortion ~ 1, design = ces_s, family = binomial) ## Warning in eval(family$initialize): non-integer #successes in a binomial glm! summary(sm0) ## ## Call: ## svyglm(formula = againstAbortion ~ 1, design = ces_s, family = binomial) ## ## Survey design: ## Called via srvyr ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.48297 0.06534 -22.7 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1.000448) ## ## Number of Fisher Scoring iterations: 4 d. compare the predicted proportions with the raw proportions we calculated earlier This undoes the log-odds (logit) transform: exp(coef(m0)) / (1+exp(coef(m0))) ## (Intercept) ## 0.1851188 exp(coef(sm0)) / (1+exp(coef(sm0))) ## (Intercept) ## 0.184979 The answer is the same as for the simple unweighted and weighted proportions, respectively. 7.6 Slopes Now, having completed the traditional step of fitting an intercept-only model, we can give the slopes a go. The Anova command in the car package works for svyglm models as before. 7.6.1 Activity Regress againstAbortion on importance, education, and gender, and interpret what you find. 7.6.2 Answer sm1 &lt;- svyglm(againstAbortion ~ importance + education + gender, design = ces_s, family = binomial) ## Warning in eval(family$initialize): non-integer #successes in a binomial glm! summary(sm1) ## ## Call: ## svyglm(formula = againstAbortion ~ importance + education + gender, ## design = ces_s, family = binomial) ## ## Survey design: ## Called via srvyr ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.8204 0.2962 -12.897 &lt; 2e-16 *** ## importancenotvery 0.4606 0.3481 1.323 0.1858 ## importancesomewhat 1.3287 0.2715 4.894 1.06e-06 *** ## importancevery 3.1405 0.2619 11.993 &lt; 2e-16 *** ## educationcollege 0.4452 0.2278 1.954 0.0508 . ## educationhigher 0.3301 0.3046 1.084 0.2786 ## educationHS 0.5692 0.2269 2.508 0.0122 * ## educationlessHS 1.0307 0.2468 4.177 3.07e-05 *** ## educationsomePS 0.1439 0.2806 0.513 0.6081 ## genderMale 0.3299 0.1482 2.225 0.0261 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 0.973961) ## ## Number of Fisher Scoring iterations: 5 To interpret those categorical predictors, it will help to check what the levels are: levels(ces$importance) ## [1] &quot;not&quot; &quot;notvery&quot; &quot;somewhat&quot; &quot;very&quot; So not is the comparison level. levels(ces$education) ## [1] &quot;bachelors&quot; &quot;college&quot; &quot;higher&quot; &quot;HS&quot; &quot;lessHS&quot; &quot;somePS&quot; bachelors is the comparison level. Gender is just a binary. Example interpretations: Men were more likely to be against abortion (log-odds 0.33 more) People for whom religion was very important were more likely than those who said not important at all to be against abortion (log-odds 3.14) You could get the odds ratios like so: exp(coef(sm1)) %&gt;% round(2) ## (Intercept) importancenotvery importancesomewhat importancevery ## 0.02 1.59 3.78 23.12 ## educationcollege educationhigher educationHS educationlessHS ## 1.56 1.39 1.77 2.80 ## educationsomePS genderMale ## 1.15 1.39 So the odds ratio of very v not important is 23.1. The ggeffects package also works with survey models: library(ggeffects) ggeffect(sm1, terms = c(&quot;education&quot;, &quot;importance&quot;)) %&gt;% plot() + ylim(0,1) ## Registered S3 methods overwritten by &#39;lme4&#39;: ## method from ## cooks.distance.influence.merMod car ## influence.merMod car ## dfbeta.influence.merMod car ## dfbetas.influence.merMod car ## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will ## replace the existing scale. 7.7 Diagnostics Many of the diagnostic check we previously encountered work here too. Here are the VIFs: vif(sm1) ## GVIF Df GVIF^(1/(2*Df)) ## importance 1.052799 3 1.008612 ## education 1.066741 5 1.006482 ## gender 1.039299 1 1.019460 My favorite, the DFBETA plots: dfbetaPlots(sm1) Try also: influence.measures(sm1) "]]
